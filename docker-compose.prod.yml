# Production Docker Compose
#
# This uses optimized builds with multi-stage Dockerfiles.
# Compatible with Docker and Podman on Linux and macOS.
#
# Usage:
#   Docker:  docker compose -f docker-compose.prod.yml up -d
#   Podman:  podman-compose -f docker-compose.prod.yml up -d
#
# GPU Requirements:
#   - NVIDIA GPU with CUDA support required for AI services
#   - nvidia-container-toolkit must be installed
#
# Environment Variables (Required):
#   - POSTGRES_PASSWORD: Database password (REQUIRED - no default for security)
#     Generate with: openssl rand -base64 32
#     Or use Docker secrets (see secrets section below)
#
# Environment Variables (Optional):
#   - AI_MODELS_PATH: Base path for AI models (default: /export/ai_models)
#   - FRONTEND_PORT: Host port for frontend (default: 5173, nginx serves on port 80 inside container)
#   - RTDETR_CONFIDENCE: Detection confidence threshold (default: 0.5)
#   - GPU_LAYERS: Number of GPU layers for LLM (default: 45)
#   - CTX_SIZE: LLM context window size (default: 131072)
#   - HF_CACHE: HuggingFace cache directory (default: ~/.cache/huggingface)
#
# Docker Secrets Support:
#   For enhanced security, you can use Docker secrets instead of environment variables.
#   Create secrets/postgres_password.txt with your password, then uncomment the secrets
#   sections below. The container will read the password from /run/secrets/postgres_password.

services:
  postgres:
    image: postgres:16-alpine
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-security}
      # SECURITY: No default password - must be explicitly set via environment or secrets
      # Option 1: Set POSTGRES_PASSWORD environment variable (e.g., in .env file)
      # Option 2: Use Docker secrets (uncomment secrets section below)
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:?POSTGRES_PASSWORD must be set - run ./setup.sh or set manually}
      - POSTGRES_DB=${POSTGRES_DB:-security}
    # Uncomment to use Docker secrets instead of environment variables:
    # secrets:
    #   - postgres_password
    # environment:
    #   - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${POSTGRES_USER:-security} -d ${POSTGRES_DB:-security}",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 1G

  ai-detector:
    build:
      context: ./ai/rtdetr
      dockerfile: Dockerfile
    ports:
      - "8090:8090"
    volumes:
      - ${HF_CACHE:-~/.cache/huggingface}:/cache/huggingface
    environment:
      - RTDETR_CONFIDENCE=${RTDETR_CONFIDENCE:-0.5}
      - RTDETR_MODEL_PATH=${RTDETR_MODEL_PATH:-PekingU/rtdetr_r50vd_coco_o365}
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import httpx; r = httpx.get('http://localhost:8090/health'); exit(0 if r.status_code == 200 else 1)",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ai-llm:
    build:
      context: ./ai/nemotron
      dockerfile: Dockerfile
    ports:
      - "8091:8091"
    volumes:
      - ${AI_MODELS_PATH:-/export/ai_models}/nemotron/nemotron-3-nano-30b-a3b-q4km:/models:ro
    environment:
      - GPU_LAYERS=${GPU_LAYERS:-35}
      - CTX_SIZE=${CTX_SIZE:-131072}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8091/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 120s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Florence-2 vision-language model for dense captioning and visual understanding
  ai-florence:
    build:
      context: ./ai/florence
      dockerfile: Dockerfile
    ports:
      - "8092:8092"
    volumes:
      - ${AI_MODELS_PATH:-/export/ai_models}/model-zoo/florence-2-large:/models/florence-2-large:ro
    environment:
      - MODEL_PATH=/models/florence-2-large
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8092/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # CLIP ViT-L model for entity re-identification embeddings
  ai-clip:
    build:
      context: ./ai/clip
      dockerfile: Dockerfile
    ports:
      - "8093:8093"
    volumes:
      - ${AI_MODELS_PATH:-/export/ai_models}/model-zoo/clip-vit-l:/models/clip-vit-l:ro
    environment:
      - CLIP_MODEL_PATH=/models/clip-vit-l
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8093/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Combined enrichment service for vehicle, pet, and clothing classification
  ai-enrichment:
    build:
      context: ./ai/enrichment
      dockerfile: Dockerfile
    ports:
      - "8094:8094"
    volumes:
      - ${AI_MODELS_PATH:-/export/ai_models}/model-zoo/vehicle-segment-classification:/models/vehicle-segment-classification:ro
      - ${AI_MODELS_PATH:-/export/ai_models}/model-zoo/pet-classifier:/models/pet-classifier:ro
      - ${AI_MODELS_PATH:-/export/ai_models}/model-zoo/fashion-clip:/models/fashion-clip:ro
      - ${AI_MODELS_PATH:-/export/ai_models}/model-zoo/depth-anything-v2-small:/models/depth-anything-v2-small:ro
    environment:
      - VEHICLE_MODEL_PATH=/models/vehicle-segment-classification
      - PET_MODEL_PATH=/models/pet-classifier
      - CLOTHING_MODEL_PATH=/models/fashion-clip
      - DEPTH_MODEL_PATH=/models/depth-anything-v2-small
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8094/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 180s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile.prod
    ports:
      - "8000:8000"
    volumes:
      # :U tells Podman to recursively chown the volume to match container user (appuser)
      # Docker ignores the :U flag, making this backward compatible
      - ./backend/data:/app/data:U
      - ${CAMERA_PATH:-/export/foscam}:/cameras:ro
      - ${AI_MODELS_PATH:-/export/ai_models}/model-zoo:/models/model-zoo:ro,z
    environment:
      # SECURITY: Uses same POSTGRES_PASSWORD as postgres service (must be set)
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-security}:${POSTGRES_PASSWORD:?POSTGRES_PASSWORD must be set}@postgres:5432/${POSTGRES_DB:-security}
      - REDIS_URL=redis://redis:6379
      - RTDETR_URL=http://ai-detector:8090
      - NEMOTRON_URL=http://ai-llm:8091
      - FLORENCE_URL=http://ai-florence:8092
      - CLIP_URL=http://ai-clip:8093
      - ENRICHMENT_URL=http://ai-enrichment:8094
      - FRONTEND_URL=http://frontend:80
      - FOSCAM_BASE_PATH=${FOSCAM_BASE_PATH:-/cameras}
      - DEBUG=${DEBUG:-false}
      - FAST_PATH_CONFIDENCE_THRESHOLD=${FAST_PATH_CONFIDENCE_THRESHOLD:-0.90}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      # ai-detector:
      #   condition: service_healthy
      # ai-llm:
      #   condition: service_healthy
      # ai-florence:
      #   condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import httpx; r = httpx.get('http://localhost:8000/api/system/health/ready'); exit(0 if r.status_code == 200 else 1)",
        ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G

  redis:
    image: redis:7.4-alpine3.21
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --appendfsync everysec
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
    ports:
      - "${FRONTEND_PORT:-5173}:80"
    # NOTE: VITE_* environment variables are NOT used at runtime.
    # Vite bakes these values at build time. The frontend uses relative URLs
    # (empty BASE_URL), and nginx proxies /api and /ws to the backend.
    # See frontend/nginx.conf for proxy configuration.
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:80",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - security-net
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M

  # =============================================================================
  # Monitoring Stack (Optional)
  # =============================================================================
  # To enable monitoring: podman-compose --profile monitoring -f docker-compose.prod.yml up -d
  # Access Grafana at http://localhost:3001 (admin/admin)
  # Access Prometheus at http://localhost:9090

  prometheus:
    image: prom/prometheus:v2.48.0
    profiles:
      - monitoring
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=15d"
      - "--web.enable-lifecycle"
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:9090/-/healthy",
        ]
      interval: 15s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - security-net

  grafana:
    image: grafana/grafana:10.2.3
    profiles:
      - monitoring
    ports:
      - "3002:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3002
      - GF_INSTALL_PLUGINS=marcusolsson-json-datasource
    depends_on:
      prometheus:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:3000/api/health",
        ]
      interval: 15s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - security-net

  redis-exporter:
    image: oliver006/redis_exporter:v1.55.0
    profiles:
      - monitoring
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis:6379
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:9121/metrics",
        ]
      interval: 15s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - security-net

  json-exporter:
    image: prometheuscommunity/json-exporter:v0.6.0
    profiles:
      - monitoring
    ports:
      - "7979:7979"
    volumes:
      - ./monitoring/json-exporter-config.yml:/etc/json-exporter/config.yml:ro
    command:
      - "--config.file=/etc/json-exporter/config.yml"
    restart: unless-stopped
    networks:
      - security-net

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  security-net:
    driver: bridge
# Docker Secrets (optional - for enhanced security)
# Uncomment to use file-based secrets instead of environment variables.
# Create the secrets directory and files first:
#   mkdir -p secrets
#   openssl rand -base64 32 > secrets/postgres_password.txt
#   chmod 600 secrets/postgres_password.txt
#
# Then uncomment the secrets section in the postgres service above.
# secrets:
#   postgres_password:
#     file: ./secrets/postgres_password.txt
