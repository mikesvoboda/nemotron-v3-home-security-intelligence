# Home Security Intelligence - Environment Configuration
# Copy this file to .env and adjust values as needed.
# See docs/reference/config/env-reference.md for detailed documentation.

# =============================================================================
# PORT STANDARDIZATION AND ENVIRONMENT SEPARATION
# =============================================================================
#
# This project uses standardized ports across all environments. The same port
# numbers are used for both development and Docker deployments - only the
# hostname/network location changes between environments.
#
# Key Principle: "Build once, deploy anywhere"
# - Ports never change between environments (no 5432 in dev, 5433 in Docker)
# - Only hostnames change: localhost vs service names on docker network
#
# STANDARDIZED PORTS:
#   Backend API:        8000 (FastAPI - internal standard, not exposed to users)
#   PostgreSQL:         5432 (database internal port)
#   Redis:              6379 (cache/queue internal port)
#   YOLO26:          8095 (object detection)
#   Nemotron LLM:       8091 (LLM reasoning)
#   Florence-2:         8092 (vision-language model)
#   CLIP:               8093 (embeddings)
#   Enrichment:         8094 (multi-model enrichment)
#
# ENVIRONMENT CONFIGURATION:
#   Development (localhost):     Service URLs point to localhost
#   Docker Compose (network):    Service URLs use container service names
#
# The setup.py script automatically generates correct URLs for your environment:
# - Run ./setup.sh to configure ports and generate .env
# - OR manually set hostnames/service names while keeping standard ports
#
# =============================================================================
# DATABASE
# =============================================================================
# ╔═══════════════════════════════════════════════════════════════════════════╗
# ║  SECURITY WARNING: NEVER commit real credentials to version control!     ║
# ║                                                                           ║
# ║  This file is a TEMPLATE. Copy it to .env and replace all placeholder    ║
# ║  values before use. The .env file is gitignored for your protection.     ║
# ║                                                                           ║
# ║  RECOMMENDED: Use environment-specific .env files:                        ║
# ║    - .env.development  (local dev with relaxed settings)                 ║
# ║    - .env.staging      (pre-production testing)                          ║
# ║    - .env.production   (hardened production settings)                    ║
# ║                                                                           ║
# ║  Generate secure passwords: openssl rand -base64 32                       ║
# ╚═══════════════════════════════════════════════════════════════════════════╝

# PostgreSQL database URL (required - no SQLite support)
#
# STANDARDIZED PORT: 5432 (same for development and Docker)
# The port remains constant - only the hostname changes between environments.
#
# IMPORTANT: Run ./setup.sh to generate a secure, unique configuration.
# The setup script creates unique passwords for each installation.
#
# Format: postgresql+asyncpg://<user>:<password>@<host>:<port>/<database>
#
# Environment Separation (port always 5432):
#   Native Dev:      postgresql+asyncpg://security:<PASSWORD>@localhost:5432/security
#   Docker Compose:  postgresql+asyncpg://security:<PASSWORD>@postgres:5432/security
#
# DATABASE_URL=postgresql+asyncpg://security:<GENERATED_BY_SETUP>@localhost:5432/security

# -----------------------------------------------------------------------------
# PostgreSQL Container (required for Docker deployment)
# -----------------------------------------------------------------------------
# These variables configure the PostgreSQL container in docker-compose files.
# They must match the DATABASE_URL connection parameters above.
#
# IMPORTANT: Run ./setup.sh to generate secure, unique passwords.
# DO NOT use default or example passwords in production.
#
# SECURITY BEST PRACTICES:
#   - Use a unique, strong password (minimum 32 characters recommended)
#   - Never use the same password across environments (dev/staging/prod)
#   - Rotate passwords periodically in production
#   - Consider using Docker secrets or a secrets manager for production
#
POSTGRES_USER=security
# POSTGRES_PASSWORD=<GENERATED_BY_SETUP>  # Run ./setup.sh to generate
POSTGRES_DB=security

# =============================================================================
# REDIS
# =============================================================================
# Redis connection URL
#
# STANDARDIZED PORT: 6379 (same for development and Docker)
# The port remains constant - only the hostname changes between environments.
#
# Environment Separation (port always 6379):
#   Native Dev:      redis://localhost:6379/0 (local Redis)
#   Docker Compose:  redis://redis:6379/0 (container network)
#
# For TLS: rediss://redis-host:6379/0 (note double 's', port stays 6379)
REDIS_URL=redis://localhost:6379/0

# -----------------------------------------------------------------------------
# REDIS PASSWORD AUTHENTICATION
# -----------------------------------------------------------------------------
# Redis password for authentication. Optional for local development (no password).
# SECURITY: Set this for production deployments to require authentication.
# Must match the `requirepass` value configured in Redis.
# Generate a strong password: openssl rand -base64 32
REDIS_PASSWORD=

# -----------------------------------------------------------------------------
# REDIS SSL/TLS CONFIGURATION
# -----------------------------------------------------------------------------
# Enable SSL/TLS encryption for Redis connections.
# SECURITY: Enable for production environments to encrypt data in transit.
# When True, ensures all Redis traffic (cached data, session info, alerts) is encrypted.
REDIS_SSL_ENABLED=false

# SSL certificate verification mode:
#   'none'     - No verification (NOT recommended for production)
#   'optional' - Verify if certificate is provided
#   'required' - Always verify (RECOMMENDED for production)
REDIS_SSL_CERT_REQS=required

# Path to CA certificate file (PEM format) for verifying Redis server certificate.
# Required when REDIS_SSL_CERT_REQS is 'required' or 'optional'.
# REDIS_SSL_CA_CERTS=/path/to/redis-ca.crt

# Path to client certificate file (PEM format) for mutual TLS (mTLS) authentication.
# Optional - only needed if Redis server requires client certificates.
# REDIS_SSL_CERTFILE=/path/to/redis-client.crt

# Path to client private key file (PEM format) for mutual TLS (mTLS) authentication.
# Required if REDIS_SSL_CERTFILE is provided.
# REDIS_SSL_KEYFILE=/path/to/redis-client.key

# Verify that the Redis server's certificate hostname matches.
# Should be True for production. Set to False only for testing with self-signed certs.
REDIS_SSL_CHECK_HOSTNAME=true

# =============================================================================
# AI SERVICES (containerized with GPU passthrough via Podman)
# =============================================================================
# STANDARDIZED PORTS (same for development and Docker):
#   YOLO26:           8095 (ai-yolo26 service)
#   Nemotron LLM:     8091 (ai-llm service)
#   Florence-2:       8092 (ai-florence service)
#   CLIP:             8093 (ai-clip service)
#   Enrichment:       8094 (ai-enrichment service)
#
# The ports remain constant - only the hostname changes between environments.

# YOLO26 object detection service
# WARNING: Use HTTPS in production to prevent man-in-the-middle (MITM) attacks.
#          HTTP is acceptable for local development only.
#
# Environment Separation (port always 8095):
#   Native Dev:      http://localhost:8095 (local service)
#   Docker Compose:  http://ai-yolo26:8095 (container network)
YOLO26_URL=http://localhost:8095

# Nemotron LLM risk analysis service (via llama.cpp)
# WARNING: Use HTTPS in production to prevent man-in-the-middle (MITM) attacks.
#          HTTP is acceptable for local development only.
#
# Environment Separation (port always 8091):
#   Native Dev:      http://localhost:8091 (local service)
#   Docker Compose:  http://ai-llm:8091 (container network)
NEMOTRON_URL=http://localhost:8091

# Florence-2 vision-language extraction service (optional)
# Environment Separation (port always 8092):
#   Native Dev:      http://localhost:8092 (local service)
#   Docker Compose:  http://ai-florence:8092 (container network)
FLORENCE_URL=http://localhost:8092

# CLIP entity re-identification service (optional)
# Environment Separation (port always 8093):
#   Native Dev:      http://localhost:8093 (local service)
#   Docker Compose:  http://ai-clip:8093 (container network)
CLIP_URL=http://localhost:8093

# Combined enrichment service (optional)
# Environment Separation (port always 8094):
#   Native Dev:      http://localhost:8094 (local service)
#   Docker Compose:  http://ai-enrichment:8094 (container network)
ENRICHMENT_URL=http://localhost:8094

# Lightweight enrichment service for GPU 1 (A400 4GB)
# Environment Separation (port always 8096):
#   Native Dev:      http://localhost:8096 (local service)
#   Docker Compose:  http://ai-enrichment-light:8096 (container network)
ENRICHMENT_LIGHT_URL=http://localhost:8096

# -----------------------------------------------------------------------------
# Enrichment Model Assignment
# -----------------------------------------------------------------------------
# Configure which enrichment service hosts each model.
# Set to 'light' for GPU 1 (A400 4GB) or 'heavy' for GPU 0 (A5500 24GB).
# Models assigned to 'light' are loaded on ai-enrichment-light:8096.
# Models assigned to 'heavy' are loaded on ai-enrichment:8094.
#
# Default assignments optimize for the A400's limited 4GB VRAM:
#   Light models (~1.2GB total): pose, threat, reid, pet, depth
#   Heavy models (~4.3GB total): vehicle, clothing, action, demographics
#
# Adjust based on your GPU configuration and VRAM requirements.
ENRICHMENT_POSE_SERVICE=light
ENRICHMENT_THREAT_SERVICE=light
ENRICHMENT_REID_SERVICE=light
ENRICHMENT_PET_SERVICE=light
ENRICHMENT_DEPTH_SERVICE=light
ENRICHMENT_VEHICLE_SERVICE=heavy
ENRICHMENT_CLOTHING_SERVICE=heavy
ENRICHMENT_ACTION_SERVICE=heavy
ENRICHMENT_DEMOGRAPHICS_SERVICE=heavy

# -----------------------------------------------------------------------------
# AI Container Configuration
# -----------------------------------------------------------------------------
# These variables configure AI containers in docker-compose files.
GPU_LAYERS=25
CTX_SIZE=131072
YOLO26_MODEL_PATH=/models/yolo26/exports/yolo26m_fp16.engine
HF_CACHE=~/.cache/huggingface

# -----------------------------------------------------------------------------
# GPU Assignment Configuration
# -----------------------------------------------------------------------------
# Configure which GPU each AI service uses. These settings control both
# CUDA_VISIBLE_DEVICES environment variable and Podman CDI device mapping.
#
# Default configuration (optimized for dual-GPU systems like A5500 + A400):
#   GPU 0: Large models (LLM, Florence, Enrichment-heavy)
#   GPU 1: Smaller models (YOLO26, CLIP, Enrichment-light)
#
# For single-GPU systems, set all to 0:
#   GPU_LLM=0
#   GPU_AI_SERVICES=0
#
GPU_LLM=0
GPU_AI_SERVICES=1

# Per-service GPU overrides (optional - defaults fall back to GPU_AI_SERVICES or GPU_LLM)
# Memory requirements per service:
#   GPU_LLM:              ~13GB (Nemotron 70B quantized)
#   GPU_FLORENCE:         ~4GB  (Florence-2-large + inference workspace)
#   GPU_ENRICHMENT:       ~4.3GB (vehicle, fashion, demographics, action models)
#   GPU_ENRICHMENT_LIGHT: ~1.2GB (pose, threat, reid, pet, depth models)
#   GPU_CLIP:             ~550MB (ViT-L embeddings)
#   GPU_YOLO26:           ~150MB (TensorRT engine)
#
# Example for A5500 (24GB) + A400 (4GB) dual-GPU setup:
GPU_FLORENCE=0
GPU_ENRICHMENT=0
# GPU_ENRICHMENT_LIGHT=1  # Uses GPU_AI_SERVICES default (GPU 1)
# GPU_CLIP=1              # Uses GPU_AI_SERVICES default (GPU 1)
# GPU_YOLO26=1            # Uses GPU_AI_SERVICES default (GPU 1)

# Development AI Host (for docker-compose.ghcr.yml when AI runs outside compose)
# AI_HOST=host.docker.internal  # macOS with Docker
# AI_HOST=host.containers.internal  # Podman

# =============================================================================
# CAMERA INTEGRATION
# =============================================================================
# Base directory for Foscam FTP uploads.
# Cameras upload to {FOSCAM_BASE_PATH}/{camera_name}/
#
# IMPORTANT: This directory MUST exist on the host before starting containers.
# The backend container mounts this path as /cameras (read-only).
# If this directory does not exist, the backend container will fail with:
#   "Error: statfs /path: no such file or directory"
#
# Setup: mkdir -p /export/foscam (or your preferred path)
# The setup.sh script will prompt to create this directory if it doesn't exist.
FOSCAM_BASE_PATH=/export/foscam

# =============================================================================
# FILE WATCHER
# =============================================================================
# Use polling observer instead of native filesystem events.
# Set to true for Docker Desktop on macOS/Windows where inotify/FSEvents
# don't propagate through volume mounts.
# Native observers (inotify/FSEvents) are more efficient but don't work
# reliably across Docker volume boundaries.
FILE_WATCHER_POLLING=false

# Polling interval in seconds when FILE_WATCHER_POLLING=true (0.1-30.0)
# Lower values = faster detection but higher CPU usage
# Higher values = lower CPU but slower detection
FILE_WATCHER_POLLING_INTERVAL=1.0

# =============================================================================
# DETECTION SETTINGS
# =============================================================================
# Minimum confidence threshold for object detections (0.0-1.0)
DETECTION_CONFIDENCE_THRESHOLD=0.5

# =============================================================================
# FAST PATH SETTINGS
# =============================================================================
# High-confidence detections bypass batching for immediate alerts
# Confidence threshold for fast path (0.0-1.0)
FAST_PATH_CONFIDENCE_THRESHOLD=0.90

# Object types eligible for fast path (JSON array)
# FAST_PATH_OBJECT_TYPES=["person"]

# =============================================================================
# BATCH PROCESSING
# =============================================================================
# Maximum time window for grouping detections into events (seconds)
BATCH_WINDOW_SECONDS=90

# Close batch after this many seconds of inactivity
BATCH_IDLE_TIMEOUT_SECONDS=30

# =============================================================================
# RETENTION
# =============================================================================
# Days to keep events and detections
RETENTION_DAYS=30

# Days to keep log entries in database
LOG_RETENTION_DAYS=7

# =============================================================================
# CONTAINER ORCHESTRATOR
# =============================================================================
# The container orchestrator provides health monitoring and self-healing
# capabilities for AI containers (YOLO26, Nemotron, Florence-2, etc.).
# It can automatically restart unhealthy containers with exponential backoff.

# Enable container orchestration (default: true)
# Set to false to disable health monitoring and automatic restarts
# ORCHESTRATOR_ENABLED=true

# Docker/Podman host URL (default: auto-detect from DOCKER_HOST or socket)
# Common values:
#   unix:///var/run/docker.sock        - Docker (rootful)
#   unix:///run/user/1000/podman/podman.sock - Podman (rootless)
#   tcp://localhost:2375               - Docker TCP (not recommended for production)
# ORCHESTRATOR_DOCKER_HOST=unix:///var/run/docker.sock

# Seconds between health checks (5-300, default: 30)
# Lower values = faster detection but more overhead
# ORCHESTRATOR_HEALTH_CHECK_INTERVAL=30

# Timeout for health check HTTP requests in seconds (1-60, default: 5)
# ORCHESTRATOR_HEALTH_CHECK_TIMEOUT=5

# Grace period in seconds before checking newly started containers (10-600, default: 60)
# Allows time for AI models to load into GPU memory
# ORCHESTRATOR_STARTUP_GRACE_PERIOD=60

# Max consecutive failures before disabling automatic restart (1-50, default: 5)
# Prevents restart loops for persistently failing containers
# ORCHESTRATOR_MAX_CONSECUTIVE_FAILURES=5

# Base backoff time in seconds for restart attempts (1-60, default: 5.0)
# Actual delay = min(base * 2^attempt, max)
# ORCHESTRATOR_RESTART_BACKOFF_BASE=5.0

# Maximum backoff time in seconds (30-3600, default: 300 = 5 minutes)
# Caps exponential backoff to prevent excessively long waits
# ORCHESTRATOR_RESTART_BACKOFF_MAX=300.0

# =============================================================================
# GPU MONITORING
# =============================================================================
# How often to poll GPU stats via pynvml (seconds, 1.0-60.0)
# Each poll reads GPU utilization, VRAM, temperature, and power usage,
# then writes to the database and broadcasts via WebSocket.
#
# Performance impact considerations:
#   1-2s   = Real-time visibility (development/debugging)
#   5s     = Balanced responsiveness and overhead (default)
#   15-30s = Lower overhead when system is under pressure
#   60s    = Minimal monitoring for trend analysis only
#
# Increase this value if:
#   - System is under heavy CPU/disk I/O pressure
#   - AI inference pipeline is saturating GPU bandwidth
#   - Database is on slow storage (HDD, network mount)
GPU_POLL_INTERVAL_SECONDS=5.0

# Minutes of GPU history to retain in memory (1-1440)
GPU_STATS_HISTORY_MINUTES=60

# =============================================================================
# FILE DEDUPLICATION
# =============================================================================
# TTL for file deduplication entries in Redis (seconds, 60-3600)
DEDUPE_TTL_SECONDS=300

# =============================================================================
# LOGGING
# =============================================================================
# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=WARNING

# Path for rotating log file
LOG_FILE_PATH=data/logs/security.log

# Maximum size of each log file in bytes (default: 10MB)
LOG_FILE_MAX_BYTES=10485760

# Number of backup log files to keep
LOG_FILE_BACKUP_COUNT=7

# Write logs to database
LOG_DB_ENABLED=true

# Minimum log level for database logging
LOG_DB_MIN_LEVEL=DEBUG

# =============================================================================
# APPLICATION
# =============================================================================
# Enable debug mode (development only)
DEBUG=false

# API server bind address
API_HOST=0.0.0.0

# API server port
API_PORT=8000

# =============================================================================
# AUTHENTICATION (disabled by default for single-user deployment)
# =============================================================================
# Enable API key authentication
API_KEY_ENABLED=false

# Valid API keys (JSON array, hashed on startup)
# API_KEYS=["your-secure-api-key-here"]

# -----------------------------------------------------------------------------
# WebSocket Token Authentication (optional)
# -----------------------------------------------------------------------------
# Set a secret token to require authentication for WebSocket connections.
# When configured, clients must include the token as a query parameter:
#   ws://host/ws/events?token=your-secret-token-here
#   ws://host/ws/system?token=your-secret-token-here
#
# Leave empty/unset for single-user deployments where WebSocket auth is not needed.
# This is separate from API_KEY_ENABLED and can be used independently or together.
#
# Generate a secure token: openssl rand -base64 32
# WEBSOCKET_TOKEN=your-secret-token-here

# =============================================================================
# TLS/HTTPS CONFIGURATION
# =============================================================================
# This project supports two TLS configuration approaches:
# 1. Modern mode-based (RECOMMENDED) - using TLS_MODE
# 2. Legacy flag-based (DEPRECATED) - using TLS_ENABLED
#
# The modern mode-based approach is cleaner and should be used for new deployments.
# Legacy settings are kept for backward compatibility but may be removed in future versions.

# -----------------------------------------------------------------------------
# MODERN TLS CONFIGURATION (RECOMMENDED)
# -----------------------------------------------------------------------------
# TLS mode: 'disabled' (HTTP only), 'self_signed' (auto-generate), 'provided' (use existing)
TLS_MODE=disabled

# For TLS_MODE=provided: Path to TLS certificate file (PEM format)
# TLS_CERT_PATH=/path/to/server.crt

# For TLS_MODE=provided: Path to TLS private key file (PEM format)
# TLS_KEY_PATH=/path/to/server.key

# Optional: Path to CA certificate for client verification (mutual TLS)
# TLS_CA_PATH=/path/to/ca.crt

# Require and verify client certificates (mutual TLS / mTLS)
# When enabled, clients must present a valid certificate signed by TLS_CA_PATH
TLS_VERIFY_CLIENT=false

# Minimum TLS version: 'TLSv1.2' or 'TLSv1.3'
# TLSv1.2 is the minimum recommended for production; TLSv1.3 offers better security
TLS_MIN_VERSION=TLSv1.2

# -----------------------------------------------------------------------------
# HSTS PRELOAD (Advanced Security)
# -----------------------------------------------------------------------------
# Enable HSTS preload directive for inclusion in browser preload lists.
# CAUTION: Only enable for public deployments registered at hstspreload.org
# Once registered, your domain will be hardcoded into browsers to always use HTTPS.
# Requirements: max-age >= 1 year, includeSubDomains, valid HTTPS on all subdomains.
# HSTS_PRELOAD=false

# -----------------------------------------------------------------------------
# LEGACY TLS CONFIGURATION (DEPRECATED - use TLS_MODE instead)
# -----------------------------------------------------------------------------
# Enable HTTPS for the API server (use TLS_MODE=self_signed or TLS_MODE=provided instead)
TLS_ENABLED=false

# Path to TLS certificate file (use TLS_CERT_PATH instead)
# TLS_CERT_FILE=/path/to/server.crt

# Path to TLS private key file (use TLS_KEY_PATH instead)
# TLS_KEY_FILE=/path/to/server.key

# Path to CA certificate (use TLS_CA_PATH instead)
# TLS_CA_FILE=/path/to/ca.crt

# Auto-generate self-signed certificates (use TLS_MODE=self_signed instead)
TLS_AUTO_GENERATE=false

# Directory for auto-generated certificates
TLS_CERT_DIR=data/certs

# =============================================================================
# CORS
# =============================================================================
# Allowed origins (JSON array format)
# Default allows localhost on dev ports. For network access, add your server's IP:
# CORS_ORIGINS=["http://localhost:3000", "http://localhost:5173", "http://192.168.1.145:5173"]
#
# For development with access from any origin (not recommended for production):
# CORS_ORIGINS=["*"]
#
# Note: In production with nginx proxy (docker-compose.prod.yml), CORS is not
# needed because the frontend and API are served from the same origin via nginx.

# =============================================================================
# MONITORING STACK (Optional)
# =============================================================================
# Enable with: podman-compose --profile monitoring -f docker-compose.prod.yml up -d

# Prometheus data retention period (e.g., 15d, 30d, 90d)
# Adjust based on storage capacity and compliance requirements.
# Default: 15d (15 days)
PROMETHEUS_RETENTION_TIME=15d

# =============================================================================
# ELASTICSEARCH CONFIGURATION (Jaeger Storage Backend)
# =============================================================================
# Heap size for Elasticsearch JVM (default: 2g)
# Recommended: Set to 50% of available memory, max 32g
ES_HEAP_SIZE=2g

# Memory limit for Elasticsearch container (default: 4G)
# Should be at least 2x ES_HEAP_SIZE for OS cache
ES_MEMORY_LIMIT=4G

# =============================================================================
# GRAFANA MONITORING (Optional)
# =============================================================================
# Grafana admin credentials
# SECURITY: Set a strong admin password (required - no default for security)
# Generate with: openssl rand -base64 32
GF_ADMIN_USER=admin
GF_ADMIN_PASSWORD=CHANGE_ME_generate_with_openssl_rand_base64_32

# Anonymous access: disabled by default for security
# Set to true only for local development when you want read-only dashboard
# viewing without login (anonymous users get Viewer role only)
GF_AUTH_ANONYMOUS_ENABLED=false

# -----------------------------------------------------------------------------
# GRAFANA SMTP CONFIGURATION (Email Alerts)
# -----------------------------------------------------------------------------
# Enable SMTP to allow Grafana to send email alerts and notifications.
# See docs/operator/smtp-configuration.md for detailed setup instructions.
#
# SECURITY: Store SMTP credentials securely. Never commit passwords to git.
# For production, consider using Docker secrets or a secrets manager.

# Enable/disable SMTP for email alerts (default: false)
GF_SMTP_ENABLED=false

# SMTP server host and port (e.g., smtp.gmail.com:587, smtp.office365.com:587)
GF_SMTP_HOST=smtp.example.com:587

# SMTP authentication credentials
# Generate app-specific passwords for services like Gmail/Outlook
GF_SMTP_USER=
GF_SMTP_PASSWORD=

# Email address alerts will be sent from
GF_SMTP_FROM_ADDRESS=grafana@example.com

# Display name for the sender (shown in email clients)
GF_SMTP_FROM_NAME=Grafana Alerts

# TLS policy: 'OpportunisticStartTLS', 'MandatoryStartTLS', or 'NoStartTLS'
# MandatoryStartTLS is recommended for security (requires server TLS support)
GF_SMTP_STARTTLS_POLICY=MandatoryStartTLS

# Skip TLS certificate verification (NOT recommended for production)
# Set to true only for testing with self-signed certificates
GF_SMTP_SKIP_VERIFY=false

# -----------------------------------------------------------------------------
# ALERTMANAGER SMTP CONFIGURATION (Email Alerts)
# -----------------------------------------------------------------------------
# Alertmanager can send email alerts independently of Grafana.
# Both systems can use the same or different SMTP servers.
#
# To enable: Uncomment smtp settings in monitoring/alertmanager.yml
# and configure these environment variables.

# SMTP server host and port
ALERTMANAGER_SMTP_HOST=smtp.example.com:587

# Email address alerts will be sent from
ALERTMANAGER_SMTP_FROM=alertmanager@example.com

# SMTP authentication credentials
ALERTMANAGER_SMTP_USER=
ALERTMANAGER_SMTP_PASSWORD=

# =============================================================================
# FRONTEND (VITE_* vars are embedded at build time)
# =============================================================================
# Host port to expose the production frontend HTTP (default: 5173)
# Maps to container port 8080 where nginx-unprivileged listens.
FRONTEND_PORT=5173

# Host port to expose the production frontend HTTPS (default: 8443)
# Maps to container port 8443 for SSL/TLS connections.
# NOTE: Default is 8443 (unprivileged) instead of 443 to avoid requiring
# root privileges or sysctl configuration for rootless containers.
FRONTEND_HTTPS_PORT=8443

# Internal container port where nginx serves HTTP traffic (default: 8080)
# nginx-unprivileged cannot bind to ports below 1024.
# This is used for container-to-container health checks.
FRONTEND_INTERNAL_PORT=8080

# Backend API URL for Vite dev server proxy (used during `npm run dev`)
# This configures where the development proxy forwards /api and /ws requests.
# Useful for remote development when backend runs on a different host.
# Default: http://localhost:8000
VITE_DEV_BACKEND_URL=http://localhost:8000

# Backend API URL (accessed from browser, not container)
VITE_API_BASE_URL=http://localhost:8000

# WebSocket URL (accessed from browser, not container)
VITE_WS_BASE_URL=ws://localhost:8000

# =============================================================================
# OPENTELEMETRY DISTRIBUTED TRACING (NEM-1629)
# =============================================================================
# Enable OpenTelemetry for distributed tracing (default: false)
# When enabled, traces are collected and exported to the configured OTLP endpoint
OTEL_ENABLED=false

# Service name for OpenTelemetry traces (identifies this service in tracing UI)
OTEL_SERVICE_NAME=nemotron-backend

# OTLP gRPC endpoint for trace export (e.g., Jaeger, Tempo, Grafana Cloud)
# Common endpoints:
#   Jaeger:     http://jaeger:4317 (container) or http://localhost:4317 (dev)
#   Tempo:      http://tempo:4317
#   Grafana:    https://otlp-gateway-prod-us-central-0.grafana.net/otlp
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Use insecure (non-TLS) connection to OTLP endpoint (default: true for local dev)
# Set to false for production with TLS-enabled collectors
OTEL_EXPORTER_OTLP_INSECURE=true

# Base trace sampling rate (0.0-1.0) - acts as a global scaling factor
# Lower values reduce telemetry volume; 1.0 traces all requests
# The priority-based sampler uses this as a maximum for non-critical traces
OTEL_TRACE_SAMPLE_RATE=1.0

# -----------------------------------------------------------------------------
# PRIORITY-BASED TRACE SAMPLING (NEM-3793)
# -----------------------------------------------------------------------------
# Intelligent sampling that preserves important traces while reducing volume.
# All rates are 0.0-1.0 (0 = never sample, 1.0 = always sample)

# Error trace sampling rate (default: 1.0 - always sample errors)
# Errors are critical for debugging and should rarely be dropped
OTEL_SAMPLING_ERROR_RATE=1.0

# High-risk security event sampling rate (default: 1.0 - always sample)
# Events with risk_score >= 70 or alert-related operations
OTEL_SAMPLING_HIGH_RISK_RATE=1.0

# High-priority API endpoint sampling rate (default: 1.0 - always sample)
# Critical paths: /api/events, /api/alerts, /api/detections, /api/cameras
OTEL_SAMPLING_HIGH_PRIORITY_RATE=1.0

# Medium-priority endpoint sampling rate (default: 0.5 - 50%)
# Important paths: /api/timeline, /api/system, /api/settings, /api/notifications
OTEL_SAMPLING_MEDIUM_PRIORITY_RATE=0.5

# Background task sampling rate (default: 0.1 - 10%)
# Noisy paths: /health, /metrics, /api/health, /api/debug
OTEL_SAMPLING_BACKGROUND_RATE=0.1

# Default sampling rate for unclassified spans (default: 0.1 - 10%)
OTEL_SAMPLING_DEFAULT_RATE=0.1

# Path classification via environment variables (comma-separated, optional):
# OTEL_SAMPLING_HIGH_PRIORITY_PATHS=/api/events,/api/alerts,/api/detections
# OTEL_SAMPLING_MEDIUM_PRIORITY_PATHS=/api/timeline,/api/system
# OTEL_SAMPLING_BACKGROUND_PATHS=/health,/metrics,/api/health

# -----------------------------------------------------------------------------
# BATCH SPAN PROCESSOR TUNING (NEM-3433)
# -----------------------------------------------------------------------------
# Optimized for high-throughput production (100+ spans/sec)

# Max spans queued before dropping (default: 8192)
# Higher values allow more buffering during spikes but use more memory
OTEL_BATCH_MAX_QUEUE_SIZE=8192

# Max spans per export batch (default: 1024)
# Larger batches reduce export overhead but increase latency
OTEL_BATCH_MAX_EXPORT_BATCH_SIZE=1024

# Delay between batch exports in milliseconds (default: 2000)
# Lower values reduce trace latency but increase export frequency
OTEL_BATCH_SCHEDULE_DELAY_MS=2000

# Timeout for exporting a batch in milliseconds (default: 30000)
OTEL_BATCH_EXPORT_TIMEOUT_MS=30000
