{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "description": "Debug individual slow requests with trace-correlated profiles. Find the profile for any request using its trace ID.",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [
    {
      "asDropdown": false,
      "icon": "dashboard",
      "includeVars": false,
      "keepTime": true,
      "tags": [],
      "targetBlank": true,
      "title": "Main Profiling Dashboard",
      "tooltip": "Return to the main continuous profiling dashboard",
      "type": "link",
      "url": "/d/hsi-profiling/hsi-profiling"
    },
    {
      "asDropdown": false,
      "icon": "external link",
      "includeVars": false,
      "keepTime": true,
      "tags": [],
      "targetBlank": true,
      "title": "Jaeger Traces",
      "tooltip": "Open Jaeger in Grafana Explore to find trace IDs",
      "type": "link",
      "url": "/explore?orgId=1&left=%7B%22datasource%22:%22Jaeger%22%7D"
    },
    {
      "asDropdown": false,
      "icon": "external link",
      "includeVars": false,
      "keepTime": false,
      "tags": [],
      "targetBlank": true,
      "title": "Pyroscope UI",
      "tooltip": "Open native Pyroscope UI for advanced queries",
      "type": "link",
      "url": "http://localhost:4040"
    }
  ],
  "liveNow": false,
  "panels": [
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 100,
      "panels": [],
      "title": "Request-Level Debugging Workflow",
      "type": "row"
    },
    {
      "datasource": {
        "type": "datasource",
        "uid": "-- Dashboard --"
      },
      "description": "Step-by-step guide for debugging slow requests using trace-correlated profiles.",
      "gridPos": {
        "h": 10,
        "w": 12,
        "x": 0,
        "y": 1
      },
      "id": 1,
      "options": {
        "code": {
          "language": "plaintext",
          "showLineNumbers": false,
          "showMiniMap": false
        },
        "content": "## Request-Level Debugging Workflow\n\n### Step 1: Find Slow Requests\nUse the **Recent Slow Requests** table below to identify endpoints with high p99 latency (>500ms shown in yellow/red).\n\n### Step 2: Get the Trace ID\n- Click **Jaeger Traces** link above to open Grafana Explore\n- Search for slow traces by service name and duration\n- Copy the `trace_id` from the trace details\n\n### Step 3: View the Profile\n- Paste the trace ID into the **Trace ID** variable at the top\n- The flame graph on the right will show CPU usage for that specific request\n\n### Step 4: Identify Hotspots\n- **Wide bars** = functions consuming significant CPU time\n- **Bottom bars** = actual work being done (leaf functions)\n- **Click** on bars to zoom into specific code paths\n\n### Alternative: Use Jaeger Direct Navigation\n1. Find the trace in Jaeger (via Explore or Tracing dashboard)\n2. Click on a slow span\n3. Look for **Profiles** tab or link\n4. Click to jump directly to the corresponding Pyroscope profile",
        "mode": "markdown"
      },
      "pluginVersion": "10.2.3",
      "title": "How to Debug Slow Requests",
      "type": "text"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "CPU flame graph filtered by the trace_id variable. Paste a trace ID above to see the exact CPU profile for that request. Shows where processing time was spent during that specific distributed trace.",
      "gridPos": {
        "h": 14,
        "w": 12,
        "x": 12,
        "y": 1
      },
      "id": 2,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"$service\", trace_id=\"$trace_id\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Profile for Trace: $trace_id",
      "type": "flamegraph"
    },
    {
      "datasource": {
        "type": "datasource",
        "uid": "-- Dashboard --"
      },
      "description": "Common patterns to look for in flame graphs and what they indicate.",
      "gridPos": {
        "h": 4,
        "w": 12,
        "x": 0,
        "y": 11
      },
      "id": 3,
      "options": {
        "code": {
          "language": "plaintext",
          "showLineNumbers": false,
          "showMiniMap": false
        },
        "content": "| Pattern | Meaning | Action |\n|---------|---------|--------|\n| Wide bar in `json.dumps` | Serialization bottleneck | Cache or stream |\n| Wide bar in `db_query` | Database taking CPU | Review query/indexes |\n| Wide bar in `model.predict` | ML inference (expected) | Check batch size |\n| Wide bar in `GC collect` | Garbage collection pressure | Reduce allocations |",
        "mode": "markdown"
      },
      "pluginVersion": "10.2.3",
      "title": "Common Patterns to Look For",
      "type": "text"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 15
      },
      "id": 101,
      "panels": [],
      "title": "Slow Request Discovery",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "PBFA97CFB590B2093"
      },
      "description": "Top 20 slowest endpoints by p99 latency in the last 5 minutes. Use this to identify which endpoints need investigation. Yellow indicates >500ms, red indicates >1s.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "cellOptions": {
              "type": "auto"
            },
            "filterable": true,
            "inspect": true
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.5
              },
              {
                "color": "red",
                "value": 1
              }
            ]
          },
          "unit": "s"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "http_route"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 350
              },
              {
                "id": "displayName",
                "value": "Endpoint"
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Value"
            },
            "properties": [
              {
                "id": "displayName",
                "value": "p99 Latency"
              },
              {
                "id": "custom.cellOptions",
                "value": {
                  "mode": "gradient",
                  "type": "gauge"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 10,
        "w": 12,
        "x": 0,
        "y": 16
      },
      "id": 4,
      "options": {
        "cellHeight": "sm",
        "footer": {
          "countRows": false,
          "enablePagination": true,
          "fields": "",
          "reducer": ["sum"],
          "show": false
        },
        "showHeader": true,
        "sortBy": [
          {
            "desc": true,
            "displayName": "p99 Latency"
          }
        ]
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "exemplar": false,
          "expr": "topk(20, histogram_quantile(0.99, sum by (le, http_route) (rate(http_request_duration_seconds_bucket{job=\"$service\"}[5m]))))",
          "format": "table",
          "instant": true,
          "legendFormat": "__auto",
          "range": false,
          "refId": "A"
        }
      ],
      "title": "Recent Slow Requests (p99 Latency by Endpoint)",
      "transformations": [
        {
          "id": "organize",
          "options": {
            "excludeByName": {
              "Time": true
            },
            "indexByName": {},
            "renameByName": {}
          }
        }
      ],
      "type": "table"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "PBFA97CFB590B2093"
      },
      "description": "Distribution of request latencies for the selected service. Helps identify if there are distinct slow request populations (bimodal distribution).",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "fillOpacity": 80,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineWidth": 1
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 10,
        "w": 12,
        "x": 12,
        "y": 16
      },
      "id": 5,
      "options": {
        "bucketCount": 30,
        "bucketOffset": 0,
        "bucketSize": 0,
        "combine": false,
        "legend": {
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        }
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "expr": "sum(rate(http_request_duration_seconds_bucket{job=\"$service\"}[5m])) by (le)",
          "format": "heatmap",
          "instant": false,
          "legendFormat": "{{le}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Request Latency Distribution - $service",
      "type": "histogram"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 26
      },
      "id": 102,
      "panels": [],
      "title": "Service Latency Trends",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "PBFA97CFB590B2093"
      },
      "description": "Service latency percentiles over time (p50, p95, p99). Use this to correlate slow periods with deployments, load changes, or incidents.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "Latency",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "line"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.5
              },
              {
                "color": "red",
                "value": 1
              }
            ]
          },
          "unit": "s"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "p50"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "green",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "p95"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "yellow",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "p99"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "red",
                  "mode": "fixed"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 27
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": ["mean", "max", "last"],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{job=\"$service\"}[5m])) by (le))",
          "legendFormat": "p50",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job=\"$service\"}[5m])) by (le))",
          "legendFormat": "p95",
          "range": true,
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{job=\"$service\"}[5m])) by (le))",
          "legendFormat": "p99",
          "range": true,
          "refId": "C"
        }
      ],
      "title": "Service Latency Over Time - $service",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 35
      },
      "id": 103,
      "panels": [],
      "title": "Memory Profile for Trace",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Memory allocations (object count) for the specified trace. Shows which functions created the most objects during that request. High values may indicate allocation hotspots causing GC pressure.",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 0,
        "y": 36
      },
      "id": 7,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"$service\", trace_id=\"$trace_id\"}",
          "profileTypeId": "memory:alloc_objects:count:space:bytes",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Memory Allocations (Objects) for Trace: $trace_id",
      "type": "flamegraph"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Memory bytes allocated for the specified trace. Shows which functions allocated the most memory during that request. Useful for identifying memory-intensive operations.",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 12,
        "y": 36
      },
      "id": 8,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"$service\", trace_id=\"$trace_id\"}",
          "profileTypeId": "memory:alloc_space:bytes:space:bytes",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Memory Bytes Allocated for Trace: $trace_id",
      "type": "flamegraph"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 48
      },
      "id": 104,
      "panels": [],
      "title": "Request Rate and Errors",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "PBFA97CFB590B2093"
      },
      "description": "Request rate and error rate over time. Spikes in error rate may correlate with slow requests or resource exhaustion.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Errors"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "red",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Requests"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "blue",
                  "mode": "fixed"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 49
      },
      "id": 9,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "expr": "sum(rate(http_request_duration_seconds_count{job=\"$service\"}[1m]))",
          "legendFormat": "Requests",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "expr": "sum(rate(http_request_duration_seconds_count{job=\"$service\", status=~\"5..\"}[1m]))",
          "legendFormat": "Errors",
          "range": true,
          "refId": "B"
        }
      ],
      "title": "Request Rate and Errors - $service",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "PBFA97CFB590B2093"
      },
      "description": "Latency breakdown by endpoint. Identifies which specific endpoints contribute most to overall service latency.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "Latency",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 49
      },
      "id": 10,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "PBFA97CFB590B2093"
          },
          "editorMode": "code",
          "expr": "topk(5, histogram_quantile(0.95, sum by (le, http_route) (rate(http_request_duration_seconds_bucket{job=\"$service\"}[5m]))))",
          "legendFormat": "{{http_route}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Top 5 Slowest Endpoints (p95) - $service",
      "type": "timeseries"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["profiling", "tracing", "debugging", "requests", "performance"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": true,
          "text": "nemotron-backend",
          "value": "nemotron-backend"
        },
        "datasource": {
          "type": "grafana-pyroscope-datasource",
          "uid": "pyroscope"
        },
        "definition": "label_values(service_name)",
        "description": "Select the service to analyze. The backend service has the most comprehensive trace-to-profile correlation.",
        "hide": 0,
        "includeAll": false,
        "label": "Service",
        "multi": false,
        "name": "service",
        "options": [],
        "query": "label_values(service_name)",
        "refresh": 2,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "",
          "value": ""
        },
        "description": "Paste a trace ID (32-character hex string) to view the CPU profile for that specific request. Get trace IDs from Jaeger or the Tracing dashboard.",
        "hide": 0,
        "label": "Trace ID",
        "name": "trace_id",
        "options": [
          {
            "selected": true,
            "text": "",
            "value": ""
          }
        ],
        "query": "",
        "skipUrlSync": false,
        "type": "textbox"
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": ["30s", "1m", "5m", "15m", "30m", "1h"]
  },
  "timezone": "browser",
  "title": "HSI Request-Level Profiling",
  "uid": "hsi-request-profiling",
  "version": 1,
  "weekStart": ""
}
