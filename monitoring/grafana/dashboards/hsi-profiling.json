{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "description": "Home Security Intelligence - Continuous Profiling Dashboard with Pyroscope integration for CPU profiling via eBPF/py-spy across all AI pipeline services.",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 100,
      "panels": [],
      "title": "Profile Timeline",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "CPU profile data over time for the selected service(s). Use this panel to identify when CPU usage spikes occur and correlate with specific events.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "CPU Time (nanoseconds)",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "ns"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 24,
        "x": 0,
        "y": 1
      },
      "id": 1,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": ["service_name"],
          "labelSelector": "{service_name=~\"$service\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "metrics",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "CPU Profile Timeline - $service",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 7
      },
      "id": 102,
      "panels": [],
      "title": "Nemotron LLM (Primary - ai-llm)",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Nemotron LLM inference profiling - the most critical service for performance analysis. Profiled via eBPF for minimal overhead. Shows CPU time spent in model.generate(), tokenizer operations, and batch processing. Key hotspots: HuggingFace Transformers inference (~60-70% CPU), tokenization (~20-30%), and response formatting. Service name: ai-llm",
      "gridPos": {
        "h": 14,
        "w": 24,
        "x": 0,
        "y": 8
      },
      "id": 4,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"ai-llm\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "ai-llm (Nemotron LLM) - CPU Flame Graph",
      "type": "flamegraph"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 22
      },
      "id": 101,
      "panels": [],
      "title": "AI Detection Services",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "YOLO26 object detection service - TensorRT-optimized inference for real-time detection. Profiled via py-spy CPU sampling. Key hotspots: TensorRT inference engine execution, NMS post-processing, bounding box decoding, and tensor data transfer between CPU/GPU. Service name: ai-yolo26",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 0,
        "y": 23
      },
      "id": 3,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"ai-yolo26\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "ai-yolo26 (Object Detection) - CPU Flame Graph",
      "type": "flamegraph"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Florence-2 vision-language model for dense captioning and scene understanding. Profiled via py-spy CPU sampling. Key hotspots: Vision encoder forward pass, cross-attention layers, beam search decoding, and image preprocessing. Service name: ai-florence",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 12,
        "y": 23
      },
      "id": 5,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"ai-florence\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "ai-florence (Vision-Language) - CPU Flame Graph",
      "type": "flamegraph"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 35
      },
      "id": 103,
      "panels": [],
      "title": "AI Enrichment Services",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "CLIP embedding service for entity re-identification and similarity matching. Profiled via py-spy CPU sampling. Key hotspots: Vision transformer forward pass, image preprocessing with PIL/torchvision, embedding normalization, and optional TensorRT inference. Service name: ai-clip",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 0,
        "y": 36
      },
      "id": 7,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"ai-clip\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "ai-clip (CLIP Embeddings) - CPU Flame Graph",
      "type": "flamegraph"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Full enrichment service with vehicle classification, pet classification, FashionSigLIP, pose estimation, OSNet Re-ID, and video analytics. Profiled via py-spy CPU sampling. Key hotspots: Multi-model inference orchestration, ByteTrack tracking, supervision annotators, and batch processing. Service name: ai-enrichment",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 12,
        "y": 36
      },
      "id": 6,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"ai-enrichment\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "ai-enrichment (Full Enrichment) - CPU Flame Graph",
      "type": "flamegraph"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Lightweight enrichment service optimized for smaller GPUs (A400 4GB). Hosts pose estimation, threat detection, OSNet Re-ID, pet classification, and depth estimation. Profiled via py-spy CPU sampling. Key hotspots: TensorRT-accelerated YOLO pose/threat models, OSNet feature extraction, and model switching overhead. Service name: ai-enrichment-light",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 0,
        "y": 48
      },
      "id": 8,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"ai-enrichment-light\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "ai-enrichment-light (Lightweight Enrichment) - CPU Flame Graph",
      "type": "flamegraph"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 60
      },
      "id": 104,
      "panels": [],
      "title": "Backend Services",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "FastAPI backend service - orchestrates AI pipeline, database operations, and WebSocket broadcasts. Profiled via pyroscope-io SDK (native Python profiling). Key hotspots: SQLAlchemy ORM operations, Redis cache interactions, batch aggregation logic, async task coordination, and HTTP request handling. Service name: nemotron-backend",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 12,
        "y": 61
      },
      "id": 2,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"nemotron-backend\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "nemotron-backend (FastAPI) - CPU Flame Graph",
      "type": "flamegraph"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 73
      },
      "id": 105,
      "panels": [],
      "title": "Selected Service Detail",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Detailed flame graph for the service(s) selected in the service dropdown. Use the multi-select to compare CPU profiles across services or drill down into a specific service.",
      "gridPos": {
        "h": 14,
        "w": 24,
        "x": 0,
        "y": 74
      },
      "id": 9,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=~\"$service\"}",
          "profileTypeId": "process_cpu:cpu:nanoseconds:cpu:nanoseconds",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Selected Service(s) - CPU Flame Graph ($service)",
      "type": "flamegraph"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["pyroscope", "profiling", "performance", "cpu", "ai", "observability"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": true,
          "text": ["ai-llm"],
          "value": ["ai-llm"]
        },
        "datasource": {
          "type": "grafana-pyroscope-datasource",
          "uid": "pyroscope"
        },
        "definition": "label_values(service_name)",
        "description": "Select service(s) to profile. Multi-select enabled for comparison. Services: ai-llm (Nemotron), ai-yolo26, ai-clip, ai-florence, ai-enrichment, ai-enrichment-light, nemotron-backend",
        "hide": 0,
        "includeAll": true,
        "label": "Service",
        "multi": true,
        "name": "service",
        "options": [],
        "query": "label_values(service_name)",
        "refresh": 2,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": ["30s", "1m", "5m", "15m", "30m", "1h"]
  },
  "timezone": "browser",
  "title": "HSI Profiling",
  "uid": "hsi-profiling",
  "version": 2,
  "weekStart": ""
}
