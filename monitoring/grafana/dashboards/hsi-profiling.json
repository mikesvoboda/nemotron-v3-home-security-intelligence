{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "description": "Home Security Intelligence - Continuous Profiling Dashboard with Pyroscope integration for CPU and memory profiling. Nemotron LLM is the primary service for performance analysis.",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 100,
      "panels": [],
      "title": "Profile Timeline",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "CPU and memory profile data over time for the selected service",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "Profile Value",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 24,
        "x": 0,
        "y": 1
      },
      "id": 1,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": ["service_name"],
          "labelSelector": "{service_name=\"$service\"}",
          "profileTypeId": "$profile_type",
          "queryType": "metrics",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Profile Timeline - $service ($profile_type)",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 7
      },
      "id": 102,
      "panels": [],
      "title": "Nemotron LLM (Primary)",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Nemotron LLM inference profiling - the most critical service for performance analysis. Shows CPU time spent in model.generate(), tokenizer operations, and batch processing. Key hotspots: HuggingFace Transformers inference (~60-70% CPU), tokenization (~20-30%), and response formatting.",
      "gridPos": {
        "h": 14,
        "w": 24,
        "x": 0,
        "y": 8
      },
      "id": 4,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"Nemotron\"}",
          "profileTypeId": "$profile_type",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Nemotron LLM Flame Graph ($profile_type)",
      "type": "flamegraph"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 22
      },
      "id": 101,
      "panels": [],
      "title": "AI Pipeline Services",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "YOLO26 object detection service - TensorRT-optimized inference for real-time detection. Key hotspots: CUDA kernel execution, NMS post-processing, and tensor operations.",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 0,
        "y": 23
      },
      "id": 3,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"YOLO26\"}",
          "profileTypeId": "$profile_type",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "YOLO26 Detection ($profile_type)",
      "type": "flamegraph"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Florence-2 vision-language model for dense captioning and scene understanding. Key hotspots: Vision encoder forward pass, cross-attention layers, and beam search decoding.",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 12,
        "y": 23
      },
      "id": 5,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"Florence\"}",
          "profileTypeId": "$profile_type",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Florence-2 Vision ($profile_type)",
      "type": "flamegraph"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 35
      },
      "id": 103,
      "panels": [],
      "title": "Backend Services",
      "type": "row"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "FastAPI backend service - orchestrates AI pipeline, database operations, and WebSocket broadcasts. Key hotspots: SQLAlchemy ORM operations, Redis cache, batch aggregation, and async task coordination.",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 0,
        "y": 36
      },
      "id": 2,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=\"Backend\"}",
          "profileTypeId": "$profile_type",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Backend API ($profile_type)",
      "type": "flamegraph"
    },
    {
      "datasource": {
        "type": "grafana-pyroscope-datasource",
        "uid": "pyroscope"
      },
      "description": "Enrichment services - CLIP embeddings, pose estimation, threat detection, and demographic analysis. Runs on dedicated GPU for batch enrichment workloads.",
      "gridPos": {
        "h": 12,
        "w": 12,
        "x": 12,
        "y": 36
      },
      "id": 6,
      "options": {
        "minPercentage": 0.1,
        "showFlameGraph": true,
        "showTable": true,
        "showTopTable": true
      },
      "pluginVersion": "10.2.3",
      "targets": [
        {
          "datasource": {
            "type": "grafana-pyroscope-datasource",
            "uid": "pyroscope"
          },
          "groupBy": [],
          "labelSelector": "{service_name=~\"ai-enrichment.*|ai-clip\"}",
          "profileTypeId": "$profile_type",
          "queryType": "profile",
          "refId": "A",
          "spanSelector": []
        }
      ],
      "title": "Enrichment Services ($profile_type)",
      "type": "flamegraph"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["pyroscope", "profiling", "performance", "nemotron", "ai"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": true,
          "text": "Nemotron",
          "value": "Nemotron"
        },
        "description": "Select the service to profile (Nemotron is default - primary LLM service)",
        "hide": 0,
        "includeAll": false,
        "label": "Service",
        "multi": false,
        "name": "service",
        "options": [
          {
            "selected": true,
            "text": "Nemotron",
            "value": "Nemotron"
          },
          {
            "selected": false,
            "text": "YOLO26",
            "value": "YOLO26"
          },
          {
            "selected": false,
            "text": "Florence",
            "value": "Florence"
          },
          {
            "selected": false,
            "text": "Backend",
            "value": "Backend"
          }
        ],
        "query": "Nemotron,YOLO26,Florence,Backend",
        "queryValue": "",
        "skipUrlSync": false,
        "type": "custom"
      },
      {
        "current": {
          "selected": true,
          "text": "cpu",
          "value": "process_cpu:cpu:nanoseconds:cpu:nanoseconds"
        },
        "description": "Select the profile type (CPU or Memory)",
        "hide": 0,
        "includeAll": false,
        "label": "Profile Type",
        "multi": false,
        "name": "profile_type",
        "options": [
          {
            "selected": true,
            "text": "cpu",
            "value": "process_cpu:cpu:nanoseconds:cpu:nanoseconds"
          },
          {
            "selected": false,
            "text": "memory",
            "value": "memory:alloc_objects:count:space:bytes"
          }
        ],
        "query": "cpu : process_cpu:cpu:nanoseconds:cpu:nanoseconds,memory : memory:alloc_objects:count:space:bytes",
        "queryValue": "",
        "skipUrlSync": false,
        "type": "custom"
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": ["30s", "1m", "5m", "15m", "30m", "1h"]
  },
  "timezone": "browser",
  "title": "HSI Profiling",
  "uid": "hsi-profiling",
  "version": 1,
  "weekStart": ""
}
