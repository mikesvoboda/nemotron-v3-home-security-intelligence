"""Prompt evaluation dataset loader for synthetic scenarios.

This module provides utilities for loading synthetic evaluation scenarios
from the data/synthetic directory structure generated by NeMo Data Designer.

Each scenario folder contains:
- expected_labels.json - Ground truth with risk score ranges
- scenario_spec.json - Full scenario specification
- metadata.json - Generation metadata
- media/ - Generated images/videos (optional)

Example Usage:
    >>> from backend.evaluation.prompt_eval_dataset import (
    ...     load_synthetic_eval_dataset,
    ...     get_samples_by_category,
    ... )
    >>>
    >>> samples = load_synthetic_eval_dataset()
    >>> print(f"Loaded {len(samples)} samples")
    >>> by_category = get_samples_by_category(samples)
    >>> print(f"Categories: {list(by_category.keys())}")
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)

# Default data directory relative to project root
DEFAULT_DATA_DIR = Path("data/synthetic")


@dataclass
class PromptEvalSample:
    """A single prompt evaluation sample from synthetic data.

    Attributes:
        scenario_id: Unique identifier for the scenario (folder name)
        category: Category of the scenario (normal, suspicious, threats)
        media_path: Path to the first media file, if available
        expected_risk_range: Tuple of (min_score, max_score) for expected risk
        expected_risk_level: Expected risk level (low, medium, high, critical)
        expected_factors: List of expected risk factors
        scenario_spec: Full scenario specification dictionary
        metadata: Generation metadata dictionary
        expected_labels: Full expected labels dictionary
    """

    scenario_id: str
    category: str
    media_path: Path | None
    expected_risk_range: tuple[int, int]
    expected_risk_level: str
    expected_factors: list[str]
    scenario_spec: dict[str, Any] = field(default_factory=dict)
    metadata: dict[str, Any] = field(default_factory=dict)
    expected_labels: dict[str, Any] = field(default_factory=dict)

    def __post_init__(self) -> None:
        """Validate sample data after initialization."""
        min_score, max_score = self.expected_risk_range
        if not (0 <= min_score <= max_score <= 100):
            logger.warning(
                "Invalid risk range for %s: (%d, %d)",
                self.scenario_id,
                min_score,
                max_score,
            )

    @property
    def has_media(self) -> bool:
        """Check if this sample has associated media files."""
        return self.media_path is not None and self.media_path.exists()

    @property
    def media_type(self) -> str | None:
        """Get the type of media (image or video) if available."""
        if not self.media_path:
            return None
        suffix = self.media_path.suffix.lower()
        if suffix in (".png", ".jpg", ".jpeg", ".webp", ".gif"):
            return "image"
        if suffix in (".mp4", ".avi", ".mov", ".mkv", ".webm"):
            return "video"
        return "unknown"

    def get_scenario_name(self) -> str:
        """Get human-readable scenario name from spec."""
        return str(self.scenario_spec.get("name", self.scenario_id))

    def get_scenario_description(self) -> str:
        """Get scenario description from spec."""
        return str(self.scenario_spec.get("description", ""))


def _load_json_file(path: Path) -> dict[str, Any]:
    """Load a JSON file safely.

    Args:
        path: Path to the JSON file

    Returns:
        Parsed JSON as dictionary, or empty dict if loading fails
    """
    try:
        return dict(json.loads(path.read_text(encoding="utf-8")))
    except (json.JSONDecodeError, OSError) as e:
        logger.warning("Failed to load %s: %s", path, e)
        return {}


def _find_media_files(media_dir: Path) -> list[Path]:
    """Find all media files in a directory.

    Args:
        media_dir: Path to the media directory

    Returns:
        Sorted list of media file paths
    """
    if not media_dir.exists() or not media_dir.is_dir():
        return []

    media_extensions = {
        ".png",
        ".jpg",
        ".jpeg",
        ".webp",
        ".gif",
        ".mp4",
        ".avi",
        ".mov",
        ".mkv",
        ".webm",
    }
    media_files = [
        f for f in media_dir.iterdir() if f.is_file() and f.suffix.lower() in media_extensions
    ]
    return sorted(media_files)


def load_synthetic_eval_dataset(
    data_dir: Path | str | None = None,
    categories: list[str] | None = None,
) -> list[PromptEvalSample]:
    """Load synthetic scenarios as prompt evaluation samples.

    Scans the data/synthetic directory structure and loads all valid
    scenarios with their expected labels and specifications.

    Args:
        data_dir: Path to the synthetic data directory.
            Defaults to data/synthetic relative to project root.
        categories: Optional list of categories to filter by.
            If None, loads all categories (normal, suspicious, threats).

    Returns:
        List of PromptEvalSample objects, one per scenario.

    Example:
        >>> samples = load_synthetic_eval_dataset()
        >>> print(f"Loaded {len(samples)} samples")
        >>> for sample in samples[:3]:
        ...     print(f"  {sample.scenario_id}: {sample.expected_risk_level}")
    """
    if data_dir is None:
        data_dir = DEFAULT_DATA_DIR
    else:
        data_dir = Path(data_dir)

    if not data_dir.exists():
        logger.warning("Synthetic data directory not found: %s", data_dir)
        return []

    samples: list[PromptEvalSample] = []

    for category_dir in sorted(data_dir.iterdir()):
        # Skip non-directories and hidden files
        if not category_dir.is_dir() or category_dir.name.startswith("."):
            continue

        category_name = category_dir.name

        # Filter by category if specified
        if categories is not None and category_name not in categories:
            continue

        for scenario_dir in sorted(category_dir.iterdir()):
            # Skip non-directories
            if not scenario_dir.is_dir():
                continue

            # Load expected labels (required)
            labels_file = scenario_dir / "expected_labels.json"
            if not labels_file.exists():
                logger.debug("Skipping %s: no expected_labels.json", scenario_dir)
                continue

            labels = _load_json_file(labels_file)
            if not labels:
                continue

            # Load optional files
            spec_file = scenario_dir / "scenario_spec.json"
            spec = _load_json_file(spec_file) if spec_file.exists() else {}

            metadata_file = scenario_dir / "metadata.json"
            metadata = _load_json_file(metadata_file) if metadata_file.exists() else {}

            # Find media files
            media_dir = scenario_dir / "media"
            media_files = _find_media_files(media_dir)

            # Extract risk information
            risk = labels.get("risk", {})
            min_score = int(risk.get("min_score", 0))
            max_score = int(risk.get("max_score", 100))
            risk_level = str(risk.get("level", "unknown"))
            expected_factors = list(risk.get("expected_factors", []))

            sample = PromptEvalSample(
                scenario_id=scenario_dir.name,
                category=category_name,
                media_path=media_files[0] if media_files else None,
                expected_risk_range=(min_score, max_score),
                expected_risk_level=risk_level,
                expected_factors=expected_factors,
                scenario_spec=spec,
                metadata=metadata,
                expected_labels=labels,
            )
            samples.append(sample)

    logger.info("Loaded %d synthetic evaluation samples", len(samples))
    return samples


def get_samples_by_category(
    samples: list[PromptEvalSample],
) -> dict[str, list[PromptEvalSample]]:
    """Group samples by category.

    Args:
        samples: List of PromptEvalSample objects

    Returns:
        Dictionary mapping category names to lists of samples

    Example:
        >>> samples = load_synthetic_eval_dataset()
        >>> by_category = get_samples_by_category(samples)
        >>> for cat, cat_samples in by_category.items():
        ...     print(f"{cat}: {len(cat_samples)} samples")
    """
    result: dict[str, list[PromptEvalSample]] = {}
    for sample in samples:
        if sample.category not in result:
            result[sample.category] = []
        result[sample.category].append(sample)
    return result


def get_samples_by_risk_level(
    samples: list[PromptEvalSample],
) -> dict[str, list[PromptEvalSample]]:
    """Group samples by expected risk level.

    Args:
        samples: List of PromptEvalSample objects

    Returns:
        Dictionary mapping risk levels to lists of samples
    """
    result: dict[str, list[PromptEvalSample]] = {}
    for sample in samples:
        level = sample.expected_risk_level
        if level not in result:
            result[level] = []
        result[level].append(sample)
    return result


def filter_samples_with_media(
    samples: list[PromptEvalSample],
    media_type: str | None = None,
) -> list[PromptEvalSample]:
    """Filter samples to only those with media files.

    Args:
        samples: List of PromptEvalSample objects
        media_type: Optional media type filter ("image" or "video")

    Returns:
        Filtered list of samples with media
    """
    result = [s for s in samples if s.has_media]
    if media_type:
        result = [s for s in result if s.media_type == media_type]
    return result


def get_scenario_summary(samples: list[PromptEvalSample]) -> dict[str, Any]:
    """Get summary statistics about the loaded samples.

    Args:
        samples: List of PromptEvalSample objects

    Returns:
        Dictionary with summary statistics
    """
    if not samples:
        return {
            "total_samples": 0,
            "by_category": {},
            "by_risk_level": {},
            "with_media": 0,
            "media_types": {},
        }

    by_category = get_samples_by_category(samples)
    by_risk_level = get_samples_by_risk_level(samples)

    media_types: dict[str, int] = {}
    for sample in samples:
        if sample.has_media:
            mt = sample.media_type or "unknown"
            media_types[mt] = media_types.get(mt, 0) + 1

    return {
        "total_samples": len(samples),
        "by_category": {cat: len(samps) for cat, samps in by_category.items()},
        "by_risk_level": {level: len(samps) for level, samps in by_risk_level.items()},
        "with_media": len(filter_samples_with_media(samples)),
        "media_types": media_types,
    }
