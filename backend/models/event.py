"""Event model for security event tracking."""

from __future__ import annotations

from datetime import UTC, datetime
from typing import TYPE_CHECKING, Any

from sqlalchemy import Boolean, CheckConstraint, DateTime, ForeignKey, Index, Integer, String, Text
from sqlalchemy.dialects.postgresql import TSVECTOR
from sqlalchemy.orm import Mapped, mapped_column, relationship

from .camera import Base
from .enums import Severity

if TYPE_CHECKING:
    from .alert import Alert
    from .camera import Camera
    from .detection import Detection
    from .event_audit import EventAudit
    from .event_detection import EventDetection
    from .event_feedback import EventFeedback


class Event(Base):
    """Event model representing a security event.

    Events are aggregated from multiple detections within a time window,
    analyzed by the LLM to determine risk level and generate summaries.

    The search_vector column is a PostgreSQL TSVECTOR that enables full-text search
    across summary, reasoning, and object types. It is populated via a database trigger.
    """

    __tablename__ = "events"

    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)
    batch_id: Mapped[str] = mapped_column(String, nullable=False)
    camera_id: Mapped[str] = mapped_column(
        String, ForeignKey("cameras.id", ondelete="CASCADE"), nullable=False
    )
    started_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), nullable=False)
    ended_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)
    risk_score: Mapped[int | None] = mapped_column(Integer, nullable=True)
    risk_level: Mapped[str | None] = mapped_column(String, nullable=True)
    summary: Mapped[str | None] = mapped_column(Text, nullable=True)
    reasoning: Mapped[str | None] = mapped_column(Text, nullable=True)
    # Full prompt sent to Nemotron LLM for analysis (for debugging/improvement)
    llm_prompt: Mapped[str | None] = mapped_column(Text, nullable=True)
    detection_ids: Mapped[str | None] = mapped_column(Text, nullable=True)
    reviewed: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    notes: Mapped[str | None] = mapped_column(Text, nullable=True)
    is_fast_path: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    # Cached object types from related detections (comma-separated string)
    # Populated by the batch aggregator when events are created
    # Has a GIN trigram index (idx_events_object_types_trgm) for efficient LIKE/ILIKE queries
    object_types: Mapped[str | None] = mapped_column(Text, nullable=True)

    # Path to generated video clip for this event (optional)
    # Generated by ClipGenerator service on event close
    clip_path: Mapped[str | None] = mapped_column(String, nullable=True)

    # Full-text search vector (PostgreSQL TSVECTOR)
    # This column is auto-populated by a database trigger on INSERT/UPDATE
    # Combines: summary, reasoning, object_types, and camera_name (via join)
    search_vector: Mapped[Any] = mapped_column(TSVECTOR, nullable=True)

    # Soft delete timestamp for preserving referential integrity
    deleted_at: Mapped[datetime | None] = mapped_column(
        DateTime(timezone=True), nullable=True, default=None
    )

    # Relationships
    camera: Mapped[Camera] = relationship("Camera", back_populates="events")
    alerts: Mapped[list[Alert]] = relationship(
        "Alert", back_populates="event", cascade="all, delete-orphan"
    )
    audit: Mapped[EventAudit | None] = relationship(
        "EventAudit", back_populates="event", uselist=False, cascade="all, delete-orphan"
    )
    # Junction table relationship for normalized detection associations
    # This provides access to EventDetection records for this event
    detection_records: Mapped[list[EventDetection]] = relationship(
        "EventDetection", back_populates="event", cascade="all, delete-orphan"
    )
    # User feedback relationship (NEM-1794)
    feedback: Mapped[EventFeedback | None] = relationship(
        "EventFeedback", back_populates="event", uselist=False, cascade="all, delete-orphan"
    )
    # Many-to-many relationship to Detection via junction table
    # This is the primary way to access detections - use this instead of parsing detection_ids
    detections: Mapped[list[Detection]] = relationship(
        "Detection",
        secondary="event_detections",
        viewonly=True,  # Managed via detection_records
        lazy="selectin",  # Eager load to avoid N+1 queries
    )

    # Indexes for common queries
    # Note: idx_events_object_types_trgm (GIN trigram index on object_types) is created
    # via Alembic migration as it requires pg_trgm extension and gin_trgm_ops operator class
    __table_args__ = (
        Index("idx_events_camera_id", "camera_id"),
        Index("idx_events_started_at", "started_at"),
        Index("idx_events_risk_score", "risk_score"),
        Index("idx_events_reviewed", "reviewed"),
        Index("idx_events_batch_id", "batch_id"),
        # GIN index for full-text search
        Index("idx_events_search_vector", "search_vector", postgresql_using="gin"),
        # NEM-1529: Composite index for combined risk_level and started_at filtering
        # Enables efficient queries like "show all high-risk events from today"
        Index("idx_events_risk_level_started_at", "risk_level", "started_at"),
        # NEM-1535: Covering index for export queries to avoid table lookups
        # Includes all columns needed for export: id, started_at, ended_at, risk_level,
        # risk_score, camera_id, object_types, summary
        Index(
            "idx_events_export_covering",
            "started_at",
            "id",
            "ended_at",
            "risk_level",
            "risk_score",
            "camera_id",
            "object_types",
            "summary",
        ),
        # NEM-1536: Partial index for unreviewed events dashboard query
        # Only indexes rows WHERE reviewed = false for efficient unreviewed count
        Index(
            "idx_events_unreviewed",
            "id",
            postgresql_where="reviewed = false",
        ),
        # CHECK constraints for enum-like columns and business rules
        CheckConstraint(
            "risk_level IS NULL OR risk_level IN ('low', 'medium', 'high', 'critical')",
            name="ck_events_risk_level",
        ),
        CheckConstraint(
            "risk_score IS NULL OR (risk_score >= 0 AND risk_score <= 100)",
            name="ck_events_risk_score_range",
        ),
        CheckConstraint(
            "ended_at IS NULL OR ended_at >= started_at",
            name="ck_events_time_order",
        ),
        # BRIN index for time-series queries on started_at (append-only chronological data)
        # Much smaller than B-tree (~1000x) and ideal for range queries on ordered timestamps
        Index(
            "ix_events_started_at_brin",
            "started_at",
            postgresql_using="brin",
        ),
    )

    @property
    def is_deleted(self) -> bool:
        """Check if this event is soft-deleted.

        Returns:
            True if deleted_at is set, False otherwise
        """
        return self.deleted_at is not None

    def soft_delete(self) -> None:
        """Soft delete this event by setting deleted_at timestamp.

        This marks the event as deleted without removing it from the database,
        preserving referential integrity with related records.
        """
        self.deleted_at = datetime.now(UTC)

    def restore(self) -> None:
        """Restore a soft-deleted event by clearing deleted_at timestamp."""
        self.deleted_at = None

    async def hard_delete(self, session: object) -> None:
        """Hard delete this event, permanently removing it from the database.

        Args:
            session: SQLAlchemy async session to use for deletion
        """
        await session.delete(self)  # type: ignore[attr-defined]

    def __repr__(self) -> str:
        return (
            f"<Event(id={self.id}, batch_id={self.batch_id!r}, "
            f"camera_id={self.camera_id!r}, risk_score={self.risk_score})>"
        )

    def get_severity(self) -> Severity | None:
        """Get the severity level for this event based on risk score.

        Uses the SeverityService to map the risk_score to a Severity enum.
        Returns None if no risk_score is set.

        Returns:
            Severity enum value or None if risk_score is not set
        """
        if self.risk_score is None:
            return None

        # Import here to avoid circular dependency
        from backend.services.severity import get_severity_service

        service = get_severity_service()
        return service.risk_score_to_severity(self.risk_score)

    @property
    def detection_id_list(self) -> list[int]:
        """Get list of detection IDs from the relationship.

        This replaces the need to parse the legacy detection_ids JSON column.
        Uses the normalized event_detections junction table.

        Returns:
            List of detection IDs associated with this event
        """
        return [d.id for d in self.detections]

    @property
    def detection_count(self) -> int:
        """Get count of detections associated with this event.

        Returns:
            Number of detections linked to this event
        """
        return len(self.detections)
