# Home Security Intelligence

> AI-powered home security monitoring with real-time object detection and LLM-based risk analysis. Self-hosted, privacy-first. Fully containerized with GPU passthrough.

## For AI Assistants (Cursor, Claude, etc.)

This file provides deployment and architecture context for LLM-powered coding assistants.

**Key entry points:**
- `docker-compose.prod.yml` - Container orchestration (9 core + 4 monitoring services)
- `backend/` - Python FastAPI backend (REST API, WebSocket, AI pipeline)
- `frontend/` - React TypeScript dashboard (Tailwind + Tremor)
- `ai/` - AI service containers (YOLO26, Nemotron, Florence, CLIP, Enrichment)

**Architecture:**
```
Cameras (FTP) --> FileWatcher --> YOLO26 --> Batch Aggregator --> Nemotron --> Dashboard
                                  (detection)                        (risk analysis)
```

## Quick Deploy (First Time)

```bash
# 1. Clone repository
git clone https://github.com/mikesvoboda/nemotron-v3-home-security-intelligence.git
cd nemotron-v3-home-security-intelligence

# 2. Configure environment
cp .env.example .env

# 3. Download AI models (~23GB, takes 10-30 min on fast connection)
./ai/download_models.sh

# 4. Start all services (builds AI containers on first run)
podman-compose -f docker-compose.prod.yml up -d

# 5. Wait for AI models to load (~2-3 min)
watch -n 5 'curl -s http://localhost:8000/api/system/health/ready'
```

**Access:** http://localhost:5173 or https://localhost:8443 (Dashboard) | http://localhost:8000/docs (API)

## Update Deployment (GHCR)

Pre-built frontend/backend containers are published to GitHub Container Registry.
AI service containers must be built locally (GPU-specific optimizations).

```bash
# Pull latest frontend + backend from GHCR
podman pull ghcr.io/mikesvoboda/nemotron-v3-home-security-intelligence/backend:latest
podman pull ghcr.io/mikesvoboda/nemotron-v3-home-security-intelligence/frontend:latest

# Rebuild AI containers if ai/ code changed
podman-compose -f docker-compose.prod.yml build ai-yolo26 ai-llm ai-florence ai-clip ai-enrichment

# Restart everything
podman-compose -f docker-compose.prod.yml down
podman-compose -f docker-compose.prod.yml up -d
```

## GPU Requirements

| VRAM | Capability | Example GPUs |
|------|------------|--------------|
| **24GB** | Full stack, all models loaded | RTX 3090, 4090, A5000, A5500, A6000 |
| **16GB** | Reduced GPU layers (`GPU_LAYERS=30`) | RTX 4080, A4000 |
| **12GB** | Minimal mode, some CPU offload | RTX 3080, 4070 Ti |

**Full stack VRAM usage:** ~23GB (Nemotron ~21GB + YOLO26 ~650MB + enrichment models)

## AI Models (~42GB total)

The download script (`./ai/download_models.sh`) fetches all required models:

| Model | Size | Purpose |
|-------|------|---------|
| Nemotron-3-Nano-30B (Q4_K_M) | ~14.7GB | Risk reasoning LLM |
| YOLO26 | ~165MB | Object detection (auto-download) |
| Florence-2-Large | ~3GB | Vision-language captions |
| CLIP-ViT-L | ~1.7GB | Entity re-identification |
| Fashion-CLIP | ~3.5GB | Clothing classification |
| Vehicle-Segment-Classification | ~100MB | Vehicle types |
| Pet-Classifier | ~100MB | Cat/dog detection |
| Depth-Anything-V2-Small | ~95MB | Depth estimation |

### Custom Model Path

Default installation path: `/export/ai_models`

To use a custom path:
```bash
# Set before running download script
export AI_MODELS_PATH=/your/custom/path
./ai/download_models.sh

# Also set when starting containers
AI_MODELS_PATH=/your/custom/path podman-compose -f docker-compose.prod.yml up -d
```

### Directory Structure (after download)

```
${AI_MODELS_PATH}/
├── nemotron/
│   └── nemotron-3-nano-30b-a3b-q4km/  # Nemotron LLM (.gguf)
└── model-zoo/
    ├── florence-2-large/              # Vision-language
    ├── clip-vit-l/                    # Embeddings
    ├── fashion-clip/                  # Clothing
    ├── vehicle-segment-classification/ # Vehicles
    ├── pet-classifier/                # Pets
    └── depth-anything-v2-small/       # Depth
```

## Services & Ports

### Core Services (9)

| Service | Port | Container | GPU | Description |
|---------|------|-----------|-----|-------------|
| Frontend HTTP | 5173 | frontend | No | React dashboard via nginx |
| Frontend HTTPS | 8443 | frontend | No | React dashboard via nginx (SSL) |
| Backend | 8000 | backend | No | FastAPI REST + WebSocket |
| PostgreSQL | 5432 | postgres | No | Event/detection storage |
| Redis | 6379 | redis | No | Queues and pub/sub |
| YOLO26 | 8095 | ai-yolo26 | Yes | Object detection |
| Nemotron | 8091 | ai-llm | Yes | Risk analysis LLM |
| Florence-2 | 8092 | ai-florence | Yes | Vision-language captions |
| CLIP | 8093 | ai-clip | Yes | Embeddings/re-identification |
| Enrichment | 8094 | ai-enrichment | Yes | Vehicle/pet/clothing analysis |

> Frontend serves via nginx in production. SSL enabled by default (self-signed). Port 5173 is also used by Vite dev server in local development.

### Monitoring Services (4)

| Service | Port | Description |
|---------|------|-------------|
| Prometheus | 9090 | Metrics collection |
| Grafana | 3000 | Dashboards |
| Redis Exporter | 9121 | Redis metrics |
| JSON Exporter | 7979 | Custom metrics |

## Common Commands

```bash
# Start all services
podman-compose -f docker-compose.prod.yml up -d

# View logs
podman-compose -f docker-compose.prod.yml logs -f backend
podman-compose -f docker-compose.prod.yml logs -f ai-llm

# Check health
curl http://localhost:8000/api/system/health/ready

# Stop services
podman-compose -f docker-compose.prod.yml down

# GPU memory check
nvidia-smi

# Database shell
podman exec -it nemotron-v3-home-security-intelligence_postgres_1 psql -U security -d security
```

## Deploy from CI/CD Containers

Pull and redeploy using pre-built containers from GitHub Container Registry:

```bash
# Pull latest containers from GHCR (main branch)
podman pull ghcr.io/mikesvoboda/nemotron-v3-home-security-intelligence/backend:latest
podman pull ghcr.io/mikesvoboda/nemotron-v3-home-security-intelligence/frontend:latest

# Redeploy
podman-compose -f docker-compose.prod.yml down
podman-compose -f docker-compose.prod.yml up -d
```

## Auto-Start on Boot

| Platform | Command |
|----------|---------|
| Linux (systemd) | `./scripts/setup-systemd.sh` |
| macOS (launchd) | `./scripts/setup-launchd.sh` |
| Windows (Task Scheduler) | `powershell -ExecutionPolicy Bypass -File .\scripts\setup-windows.ps1` |

## Troubleshooting

**Container won't start (port in use):**
```bash
ss -tlnp | grep 8000  # Find what's using the port
```

**GPU not available:**
```bash
podman run --rm --device nvidia.com/gpu=all nvidia/cuda:12.4-base nvidia-smi
```

**Out of VRAM:**
```bash
# Edit .env or docker-compose.prod.yml
GPU_LAYERS=30  # Reduce from default 35
```

**AI service slow/not responding:**
```bash
curl http://localhost:8095/health  # YOLO26
curl http://localhost:8091/health  # Nemotron
# First request after startup is slow (model loading)
```

## Documentation

| Need | Document |
|------|----------|
| All environment variables | [docs/reference/config/env-reference.md](docs/reference/config/env-reference.md) |
| AI model setup & downloads | [docs/operator/ai-installation.md](docs/operator/ai-installation.md) |
| Container configuration | [docs/operator/deployment/](docs/operator/deployment/) |
| Full operator guide | [docs/operator/](docs/operator/) |
| Development setup | [CLAUDE.md](CLAUDE.md) |
| User guide | [docs/user/README.md](docs/user/README.md) |

## Project Structure

```
nemotron-v3-home-security-intelligence/
├── docker-compose.prod.yml   # Container orchestration
├── backend/                  # FastAPI backend
│   ├── api/routes/          # REST + WebSocket endpoints
│   ├── services/            # AI pipeline, file watcher
│   └── models/              # SQLAlchemy models
├── frontend/                 # React dashboard
│   └── src/
│       ├── components/      # UI components
│       ├── hooks/           # WebSocket + data hooks
│       └── services/        # API client
├── ai/                       # AI service containers
│   ├── yolo26/              # Object detection (port 8095)
│   ├── nemotron/            # Risk reasoning LLM (port 8091)
│   ├── florence/            # Vision-language (port 8092)
│   ├── clip/                # Embeddings (port 8093)
│   └── enrichment/          # Additional models (port 8094)
└── docs/                     # Documentation
```

## Support

- **Issues:** https://github.com/mikesvoboda/nemotron-v3-home-security-intelligence/issues
- **API Docs:** http://localhost:8000/docs (when running)
