name: GPU Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  gpu-integration:
    name: GPU Integration Tests
    runs-on: [self-hosted, gpu, rtx-a5500]
    # Fork protection - only run for trusted sources
    if: >
      github.event.pull_request.head.repo.full_name == github.repository ||
      github.event_name == 'push'
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Verify GPU availability
        run: |
          nvidia-smi
          echo "GPU Memory: $(nvidia-smi --query-gpu=memory.total --format=csv,noheader)"

      - name: Set up Python
        run: |
          python3 -m venv .venv
          source .venv/bin/activate
          pip install -r backend/requirements.txt

      - name: Run GPU tests
        run: |
          source .venv/bin/activate
          # Exit code 5 means no tests collected - treat as success
          pytest backend/tests/ \
            -m "gpu" \
            -v \
            --tb=short || [ $? -eq 5 ]
        env:
          CUDA_VISIBLE_DEVICES: "0"

      - name: Run AI inference benchmarks
        run: |
          source .venv/bin/activate
          # Disable xdist and override default opts to allow benchmarks
          # (xdist auto-disables benchmarking, and pytest.ini has xdist options)
          pytest backend/tests/benchmarks/ \
            -p no:xdist \
            -o "addopts=-v --strict-markers --tb=short --timeout=30" \
            --benchmark-only \
            --benchmark-json=gpu-benchmark.json \
            -v || [ $? -eq 5 ]
        env:
          CUDA_VISIBLE_DEVICES: "0"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        with:
          name: gpu-benchmark-results
          path: gpu-benchmark.json

      - name: Check GPU memory usage
        if: always()
        run: |
          nvidia-smi --query-compute-apps=pid,used_memory --format=csv
          nvidia-smi
