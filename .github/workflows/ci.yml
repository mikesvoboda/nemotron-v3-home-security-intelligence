name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.14'
  NODE_VERSION: '20'

jobs:
  # ============================================================================
  # Backend Jobs
  # ============================================================================

  lint:
    name: Backend Lint (Ruff)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Ruff check
        run: uv run ruff check backend/

      - name: Ruff format check
        run: uv run ruff format --check backend/

      - name: Complexity check (Radon)
        run: |
          uv run radon cc backend/ -a -nc
          uv run radon mi backend/ -nc

  typecheck:
    name: Backend Type Check (Mypy)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Mypy
        run: uv run mypy backend/ --ignore-missing-imports

  unit-tests:
    name: Backend Unit Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: security_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      TEST_DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Run unit tests with coverage
        # Unit tests coverage threshold - 85% for unit tests alone
        # Combined coverage (unit + integration) should reach 95%
        # -n auto enables xdist parallelization with worksteal scheduler
        # --timeout=0 disables timeout (fixture import takes >1s in CI)
        run: |
          uv run pytest backend/tests/unit/ \
            -n auto --dist=worksteal \
            --timeout=0 \
            --cov=backend \
            --cov-config=pyproject.toml \
            --cov-report=xml:coverage-unit.xml \
            --cov-report=term-missing \
            --cov-fail-under=85 \
            --junit-xml=test-results-unit.xml \
            --durations=20 \
            -v

      - name: Upload unit test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: test-results-unit
          path: test-results-unit.xml
          retention-days: 7

      - name: Upload unit test coverage
        uses: codecov/codecov-action@v5
        with:
          files: coverage-unit.xml
          flags: backend-unit
          fail_ci_if_error: false

  # Integration tests split into 4 domain-based parallel jobs for faster execution
  # Each job runs tests for a specific domain with within-shard parallelization
  integration-tests-api:
    name: Integration Tests (API)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    # Runs in parallel with unit-tests (removed needs dependency for CI speed)
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: security_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      TEST_DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      REDIS_URL: redis://localhost:6379
      REDIS_HOST: localhost
      REDIS_PORT: 6379
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Run API integration tests
        # API tests: test_*_api.py files
        # -n0 runs tests serially to avoid database deadlocks from concurrent schema creation
        run: |
          uv run pytest backend/tests/integration/ \
            -k "test_admin_api or test_ai_audit_api or test_alerts_api or test_api_error_scenarios or test_api_errors or test_audit_api or test_cameras_api or test_detections_api or test_dlq_api or test_entities_api or test_events_api or test_http_error_codes or test_logs_api or test_media_api or test_media_security or test_metrics_api or test_notification_api or test_search_api or test_system_api or test_video_streaming or test_zones_api or test_api" \
            -n0 \
            --timeout=30 \
            --cov=backend \
            --cov-fail-under=0 \
            --cov-report=xml:coverage-integration-api.xml \
            --cov-report=term-missing \
            --junit-xml=test-results-integration-api.xml \
            --durations=20 \
            -v

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: test-results-integration-api
          path: test-results-integration-api.xml
          retention-days: 7

      - name: Upload coverage artifact
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: coverage-integration-api
          path: coverage-integration-api.xml
          retention-days: 7

  integration-tests-websocket:
    name: Integration Tests (WebSocket)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    # Runs in parallel with unit-tests (removed needs dependency for CI speed)
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: security_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      TEST_DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      REDIS_URL: redis://localhost:6379
      REDIS_HOST: localhost
      REDIS_PORT: 6379
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Run WebSocket integration tests
        # WebSocket tests: test_websocket*.py, test_broadcast*.py, test_pubsub*.py
        # -n0 runs tests serially to avoid database deadlocks from concurrent schema creation
        run: |
          uv run pytest backend/tests/integration/ \
            -k "test_websocket or test_system_broadcaster or test_redis_pubsub" \
            -n0 \
            --timeout=30 \
            --cov=backend \
            --cov-fail-under=0 \
            --cov-report=xml:coverage-integration-websocket.xml \
            --cov-report=term-missing \
            --junit-xml=test-results-integration-websocket.xml \
            --durations=20 \
            -v

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: test-results-integration-websocket
          path: test-results-integration-websocket.xml
          retention-days: 7

      - name: Upload coverage artifact
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: coverage-integration-websocket
          path: coverage-integration-websocket.xml
          retention-days: 7

  integration-tests-services:
    name: Integration Tests (Services)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    # Runs in parallel with unit-tests (removed needs dependency for CI speed)
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: security_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      TEST_DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      REDIS_URL: redis://localhost:6379
      REDIS_HOST: localhost
      REDIS_PORT: 6379
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Run Services integration tests
        # Service tests: test_*_integration.py, test_batch*.py, test_detector*.py, test_file_watcher*.py, test_circuit*.py
        # -n0 runs tests serially to avoid database deadlocks from concurrent schema creation
        run: |
          uv run pytest backend/tests/integration/ \
            -k "test_batch_aggregator_integration or test_detector_client_integration or test_file_watcher_filesystem or test_file_watcher_integration or test_circuit_breaker or test_cleanup_service or test_dlq_retry_handler_integration or test_health_monitor_integration or test_nemotron_analyzer_integration or test_nemotron_analyzer or test_vision_extraction_pipeline or test_pipeline_e2e or test_full_stack or test_audit or test_event_search or test_github_workflows or test_alembic_migrations or test_transaction_rollback" \
            -n0 \
            --timeout=30 \
            --cov=backend \
            --cov-fail-under=0 \
            --cov-report=xml:coverage-integration-services.xml \
            --cov-report=term-missing \
            --junit-xml=test-results-integration-services.xml \
            --durations=20 \
            -v

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: test-results-integration-services
          path: test-results-integration-services.xml
          retention-days: 7

      - name: Upload coverage artifact
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: coverage-integration-services
          path: coverage-integration-services.xml
          retention-days: 7

  integration-tests-models:
    name: Integration Tests (Models)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    # Runs in parallel with unit-tests (removed needs dependency for CI speed)
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: security_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      TEST_DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      REDIS_URL: redis://localhost:6379
      REDIS_HOST: localhost
      REDIS_PORT: 6379
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Run Models integration tests
        # Model tests: test_models*.py, test_database*.py, test_baseline*.py, test_alert_*.py, test_enrichment*.py, test_cache*.py
        # -n0 runs tests serially to avoid database deadlocks from concurrent schema creation
        run: |
          uv run pytest backend/tests/integration/ \
            -k "test_models or test_model_cascades or test_database or test_baseline or test_alert_dedup or test_alert_engine or test_alert_models or test_enrichment_pipeline or test_cache_service_integration" \
            -n0 \
            --timeout=30 \
            --cov=backend \
            --cov-fail-under=0 \
            --cov-report=xml:coverage-integration-models.xml \
            --cov-report=term-missing \
            --junit-xml=test-results-integration-models.xml \
            --durations=20 \
            -v

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: test-results-integration-models
          path: test-results-integration-models.xml
          retention-days: 7

      - name: Upload coverage artifact
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: coverage-integration-models
          path: coverage-integration-models.xml
          retention-days: 7

  # Merge coverage from all integration test shards
  integration-coverage-merge:
    name: Merge Integration Coverage
    runs-on: ubuntu-latest
    needs:
      [
        integration-tests-api,
        integration-tests-websocket,
        integration-tests-services,
        integration-tests-models,
      ]
    if: always()
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-integration-*
          path: coverage-reports/
          merge-multiple: true

      - name: List coverage files
        run: find coverage-reports/ -name "*.xml" | head -20

      - name: Upload merged coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          directory: coverage-reports/
          flags: backend-integration
          fail_ci_if_error: false

  # Summary job for branch protection - aggregates all integration test shards
  integration-tests-summary:
    name: Backend Integration Tests
    runs-on: ubuntu-latest
    needs:
      [
        integration-tests-api,
        integration-tests-websocket,
        integration-tests-services,
        integration-tests-models,
      ]
    if: always()
    steps:
      - name: Check integration test results
        run: |
          if [ "${{ needs.integration-tests-api.result }}" == "failure" ] || \
             [ "${{ needs.integration-tests-websocket.result }}" == "failure" ] || \
             [ "${{ needs.integration-tests-services.result }}" == "failure" ] || \
             [ "${{ needs.integration-tests-models.result }}" == "failure" ]; then
            echo "One or more integration test jobs failed"
            exit 1
          fi
          echo "All integration tests passed"

  dead-code:
    name: Dead Code Detection
    runs-on: ubuntu-latest
    # Non-blocking initially - reports issues without failing CI
    continue-on-error: true
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Run Vulture (dead code detection)
        run: uv run vulture backend/ vulture_whitelist.py --min-confidence 80

  # ============================================================================
  # Frontend Jobs
  # ============================================================================

  api-types-check:
    name: API Types Contract Check
    runs-on: ubuntu-latest
    env:
      DATABASE_URL: postgresql://user:pass@localhost/db
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install backend dependencies
        run: uv sync --extra dev --frozen

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        run: cd frontend && npm ci

      - name: Check API types are current
        run: ./scripts/generate-types.sh --check

  frontend-lint:
    name: Frontend Lint (ESLint)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: cd frontend && npm ci

      - name: ESLint
        run: cd frontend && npm run lint

      - name: Dead code detection (Knip)
        # Non-blocking initially - reports issues without failing CI
        continue-on-error: true
        run: cd frontend && npx knip

  frontend-typecheck:
    name: Frontend Type Check (TypeScript)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: cd frontend && npm ci

      - name: TypeScript check
        run: cd frontend && npm run typecheck

  frontend-tests:
    name: Frontend Tests (Vitest ${{ matrix.shard }}/8)
    runs-on: ubuntu-latest
    timeout-minutes: 3
    # Allow shard 5 to fail - it has a hanging test that needs investigation
    continue-on-error: ${{ matrix.shard == 5 }}
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4, 5, 6, 7, 8]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: cd frontend && npm ci

      - name: Run tests (shard ${{ matrix.shard }}/8)
        # Shard tests across 8 runners for faster execution and isolation
        # Coverage thresholds disabled for shards (each shard only has partial coverage)
        # --teardownTimeout ensures vitest exits even if cleanup hangs
        run: cd frontend && npx vitest run --shard=${{ matrix.shard }}/8 --teardownTimeout=5000

  # Summary job for branch protection - aggregates all Vitest shards
  frontend-tests-summary:
    name: Frontend Tests (Vitest)
    runs-on: ubuntu-latest
    needs: [frontend-tests]
    if: always()
    steps:
      - name: Check shard results
        run: |
          if [ "${{ needs.frontend-tests.result }}" == "failure" ]; then
            echo "One or more Vitest shards failed"
            exit 1
          fi
          echo "All Vitest shards passed"

  api-coverage:
    name: API Endpoint Coverage
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check API coverage
        run: ./scripts/check-api-coverage.sh

  # Primary E2E tests (Chromium) - non-blocking while stabilizing error state tests
  # Uses sharding to split tests across 4 parallel runners for 4x speed
  frontend-e2e:
    name: E2E Tests (chromium ${{ matrix.shard }})
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        shard: [1/4, 2/4, 3/4, 4/4]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: cd frontend && npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v5
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-chromium-${{ runner.os }}-${{ hashFiles('frontend/package-lock.json') }}

      - name: Install Playwright Chromium
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: cd frontend && npx playwright install chromium --with-deps

      - name: Install Playwright deps (cached)
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: cd frontend && npx playwright install-deps chromium

      - name: Run E2E tests (Chromium shard ${{ matrix.shard }})
        run: cd frontend && npx playwright test --project=chromium --shard=${{ matrix.shard }}

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: playwright-report-chromium-${{ strategy.job-index }}
          path: frontend/playwright-report/
          retention-days: 7

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: playwright-test-results-chromium-${{ strategy.job-index }}
          path: frontend/test-results/
          retention-days: 7

  # Secondary E2E tests (Firefox/WebKit) - non-blocking, informational only
  frontend-e2e-secondary:
    name: E2E Tests (${{ matrix.browser }})
    runs-on: ubuntu-latest
    # Non-blocking: These browsers are slower and flakier, failures are informational
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        browser: [firefox, webkit]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: cd frontend && npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v5
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ matrix.browser }}-${{ runner.os }}-${{ hashFiles('frontend/package-lock.json') }}

      - name: Install Playwright ${{ matrix.browser }}
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: cd frontend && npx playwright install ${{ matrix.browser }} --with-deps

      - name: Install Playwright deps (cached)
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: cd frontend && npx playwright install-deps ${{ matrix.browser }}

      - name: Run E2E tests (${{ matrix.browser }})
        run: cd frontend && npx playwright test --project=${{ matrix.browser }}

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: playwright-report-${{ matrix.browser }}
          path: frontend/playwright-report/
          retention-days: 7

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: playwright-test-results-${{ matrix.browser }}
          path: frontend/test-results/
          retention-days: 7

  # ============================================================================
  # Build Jobs (run on PRs and pushes to catch Docker issues before merge)
  # Separate jobs for backend/frontend to avoid disk space issues
  # ============================================================================

  build-backend:
    name: Build Docker (backend)
    runs-on: ubuntu-latest
    continue-on-error: true
    # Only needs lint/typecheck - runs in parallel with tests for CI speed
    needs:
      - lint
      - typecheck
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Free up disk space
        # Backend image includes heavy ML dependencies (PyTorch, transformers)
        # which require more disk space than default GitHub runners provide
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: true
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: true
          swap-storage: true

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build backend image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./backend/Dockerfile.prod
          push: false
          tags: backend:${{ github.sha }}
          cache-from: type=gha,scope=backend
          cache-to: type=gha,mode=max,scope=backend

  build-frontend:
    name: Build Docker (frontend)
    runs-on: ubuntu-latest
    continue-on-error: true
    needs:
      - frontend-lint
      - frontend-typecheck
      - frontend-tests
      - frontend-e2e
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build frontend image
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile.prod
          push: false
          tags: frontend:${{ github.sha }}
          cache-from: type=gha,scope=frontend
          cache-to: type=gha,mode=max,scope=frontend

  # ============================================================================
  # Security Validation Job
  # ============================================================================

  security-validation:
    name: Admin Endpoint Security Validation
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: security_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      TEST_DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/security_test
      REDIS_URL: redis://localhost:6379
      REDIS_HOST: localhost
      REDIS_PORT: 6379
      DEBUG: 'false'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Validate admin endpoints require DEBUG mode
        run: |
          # Run specific tests that verify admin endpoints return 403 when DEBUG=false
          # These tests are critical security validation
          # -n0 disables xdist (security tests modify global settings)
          # --timeout=0 disables timeout (fixture import takes >1s in CI)
          uv run pytest backend/tests/integration/test_admin_api.py \
            -n0 \
            --timeout=0 \
            -k "requires_debug_mode" \
            -v \
            --tb=short

      - name: Verify DEBUG=false is enforced
        run: |
          # Double-check that DEBUG is actually false in this environment
          uv run python -c "
          import os
          from backend.core.config import get_settings
          settings = get_settings()
          assert settings.debug == False, f'DEBUG should be False but is {settings.debug}'
          print('SUCCESS: DEBUG mode is correctly set to False')
          "

  # ============================================================================
  # Test Performance Audit Job
  # ============================================================================

  test-performance-audit:
    name: Test Performance Audit
    runs-on: ubuntu-latest
    continue-on-error: true
    needs:
      [
        unit-tests,
        integration-tests-api,
        integration-tests-websocket,
        integration-tests-services,
        integration-tests-models,
        frontend-e2e,
      ]
    if: always() && (needs.unit-tests.result == 'success' || needs.integration-tests-api.result == 'success' || needs.integration-tests-websocket.result == 'success' || needs.integration-tests-services.result == 'success' || needs.integration-tests-models.result == 'success' || needs.frontend-e2e.result == 'success')
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4
        with:
          version: 'latest'
          cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --frozen

      - name: Download all test results
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-*
          path: test-results/
          merge-multiple: true

      - name: Download E2E test results
        uses: actions/download-artifact@v7
        with:
          pattern: playwright-test-results-*
          path: test-results/
          merge-multiple: true
        continue-on-error: true

      - name: List downloaded artifacts
        run: find test-results/ -type f -name "*.xml" | head -30

      - name: Analyze test durations
        run: uv run python scripts/audit-test-durations.py test-results/
        env:
          UNIT_TEST_THRESHOLD: '1.0'
          INTEGRATION_TEST_THRESHOLD: '5.0'
          E2E_TEST_THRESHOLD: '10.0'
          WARN_THRESHOLD_PERCENT: '80'
